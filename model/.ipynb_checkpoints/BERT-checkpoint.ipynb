{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "import timeit\n",
    "\n",
    "from evaluator import Evaluator\n",
    "from vocab import Vocab, VocabEntry\n",
    "from utils import read_corpus, pad_sents, batch_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word types: 23437, number of word types w/ frequency >= 0: 23437\n"
     ]
    }
   ],
   "source": [
    "words, defs, ft_dict = pickle.load( open( \"../data/words_defs_dict.train\", \"rb\" ))\n",
    "\n",
    "vocab = VocabEntry.from_corpus(defs, 1000000, 0)\n",
    "for w in ft_dict:\n",
    "    vocab.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, src_pad_token_idx, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim, src_pad_token_idx)\n",
    "    emb_layer.weight.data.copy_(torch.from_numpy(weights_matrix)) #figure out what is here\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "class ModelEmbeddings(nn.Module): \n",
    "    \"\"\"\n",
    "    Class that converts input words to their embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_size, vocab, fasttext_dict):\n",
    "        \"\"\"\n",
    "        Init the Embedding layers.\n",
    "\n",
    "        @param embed_size (int): Embedding size (dimensionality)\n",
    "        @param vocab (VocabEntry)\n",
    "        \"\"\"\n",
    "        super(ModelEmbeddings, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        matrix_len = len(vocab)\n",
    "        weights_matrix = np.zeros((matrix_len, self.embed_size))\n",
    "        words_found = 0\n",
    "        #print(len(vocab), weights_matrix.shape)\n",
    "        for word, index in vocab.word2id.items():\n",
    "            try:\n",
    "                weights_matrix[index] = np.array(fasttext_dict[word])\n",
    "                words_found += 1\n",
    "            except KeyError:\n",
    "                weights_matrix[index] = np.random.normal(scale=0.6, size=(self.embed_size,))\n",
    "\n",
    "        # default values\n",
    "        src_pad_token_idx = vocab['<pad>']\n",
    "        self.source = create_emb_layer(weights_matrix, src_pad_token_idx, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseDictionary(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim, hidden_dim, vocab, ft_dict, freeze_bert = False):\n",
    "        super(ReverseDictionary, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        \n",
    "        self.ft_embedding = ModelEmbeddings(embed_dim, vocab, ft_dict)\n",
    "        #self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #Freeze bert layers\n",
    "#         if freeze_bert:\n",
    "#             for p in self.bert_layer.parameters():\n",
    "#                 p.requires_grad = False\n",
    "        \n",
    "        #Classification layer\n",
    "        self.lstm_fasttext = nn.LSTM(embed_dim, hidden_dim)\n",
    "        self.lin_layer = nn.Linear(hidden_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, bert_input, ft_input, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        embedded = self.ft_embedding.source[0](ft_input)\n",
    "        \n",
    "#         cont_reps, _ = self.bert_layer(bert_input, attention_mask = attn_masks)\n",
    "        \n",
    "        output, (cn, hn) = self.lstm_fasttext(embedded.unsqueeze(1))\n",
    "        \n",
    "#         cls_rep = cont_reps[:, 0]\n",
    "        \n",
    "        #print(cn.squeeze(1).shape, cls_rep.shape)\n",
    "\n",
    "        toLinear = cn.squeeze(1) # torch.cat([cls_rep, cn.squeeze(1)], 1)\n",
    "\n",
    "        #Obtaining the representation of [CLS] head\n",
    "        \n",
    "        #feed cls_rep to -> fasttext layer\n",
    "        projected = self.lin_layer(toLinear)\n",
    "\n",
    "        return projected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ReverseDictionary(300, 300, vocab, ft_dict)\n",
    "loss_function = nn.L1Loss(reduction='mean')\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sents = vocab.words2indices(defs)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_len = max(len(x) for x in int_sents)\n",
    "sents_ft_id = [torch.tensor(i, dtype=torch.long, device=\"cpu\") for i in int_sents]\n",
    "sents_bert_id = []\n",
    "masks = []\n",
    "for d in defs:\n",
    "    tokens = ['[CLS]'] + d + ['[SEP]']\n",
    "    padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [0 for _ in range(len(padded_tokens))]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids = torch.tensor(token_ids).unsqueeze(0) \n",
    "    attn_mask = torch.tensor(attn_mask).unsqueeze(0) \n",
    "    sents_bert_id.append(token_ids)\n",
    "    masks.append(attn_mask)\n",
    "assert(len(sents_bert_id) == len(masks))\n",
    "assert(len(masks) == len(sents_ft_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fault\n",
      "tensor(0.0373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "0 tensor(0.0373, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.07528866303618997\n",
      "fault\n",
      "tensor(0.0215, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "1 tensor(0.0215, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.12296652398072183\n",
      "fault\n",
      "tensor(0.0143, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "2 tensor(0.0143, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.15302758500911295\n",
      "fault\n",
      "tensor(0.0118, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "3 tensor(0.0118, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.18385137396398932\n",
      "fault\n",
      "tensor(0.0079, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "4 tensor(0.0079, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.21333987801335752\n",
      "fault\n",
      "tensor(0.0079, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "5 tensor(0.0079, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.24540373601485044\n",
      "fault\n",
      "tensor(0.0046, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "6 tensor(0.0046, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.30209948297124356\n",
      "fault\n",
      "tensor(0.0063, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "7 tensor(0.0063, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.33472859498579055\n",
      "fault\n",
      "tensor(0.0064, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "8 tensor(0.0064, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.36549600295256823\n",
      "fault\n",
      "tensor(0.0094, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "9 tensor(0.0094, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.41150753397960216\n",
      "fault\n",
      "tensor(0.0080, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "10 tensor(0.0080, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.4634625749895349\n",
      "fault\n",
      "tensor(0.0044, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "11 tensor(0.0044, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.515521771972999\n",
      "fault\n",
      "tensor(0.0055, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "12 tensor(0.0055, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.5641042550560087\n",
      "fault\n",
      "tensor(0.0035, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "13 tensor(0.0035, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.6122549249557778\n",
      "fault\n",
      "tensor(0.0049, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "14 tensor(0.0049, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.6484625249868259\n",
      "fault\n",
      "tensor(0.0026, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "15 tensor(0.0026, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.6812780710170045\n",
      "fault\n",
      "tensor(0.0040, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "16 tensor(0.0040, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.721279943943955\n",
      "fault\n",
      "tensor(0.0022, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "17 tensor(0.0022, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.7526575289666653\n",
      "fault\n",
      "tensor(0.0040, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "18 tensor(0.0040, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.7831682889955118\n",
      "fault\n",
      "tensor(0.0038, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "19 tensor(0.0038, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.8135171399917454\n",
      "fault\n",
      "tensor(0.0045, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "20 tensor(0.0045, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.845296959974803\n",
      "fault\n",
      "tensor(0.0044, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "21 tensor(0.0044, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.876175126992166\n",
      "fault\n",
      "tensor(0.0031, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "22 tensor(0.0031, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.9128758889855817\n",
      "fault\n",
      "tensor(0.0038, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "23 tensor(0.0038, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.9499596980167553\n",
      "fault\n",
      "tensor(0.0030, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "24 tensor(0.0030, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.9805884700035676\n",
      "fault\n",
      "tensor(0.0042, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "25 tensor(0.0042, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.0114587809657678\n",
      "fault\n",
      "tensor(0.0024, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "26 tensor(0.0024, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.0431775420438498\n",
      "fault\n",
      "tensor(0.0043, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "27 tensor(0.0043, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.08388906205073\n",
      "fault\n",
      "tensor(0.0019, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "28 tensor(0.0019, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.11616379104089\n",
      "fault\n",
      "tensor(0.0035, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "29 tensor(0.0035, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.1570137200178578\n",
      "fault\n",
      "tensor(0.0016, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "30 tensor(0.0016, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.195269005955197\n",
      "fault\n",
      "tensor(0.0030, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "31 tensor(0.0030, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.2312495940132067\n",
      "fault\n",
      "tensor(0.0013, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "32 tensor(0.0013, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.2679996460210532\n",
      "fault\n",
      "tensor(0.0028, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "33 tensor(0.0028, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.303041866980493\n",
      "fault\n",
      "tensor(0.0014, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "34 tensor(0.0014, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.3398164169630036\n",
      "fault\n",
      "tensor(0.0032, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "35 tensor(0.0032, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.379075380973518\n",
      "fault\n",
      "tensor(0.0024, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "36 tensor(0.0024, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.4171755430288613\n",
      "fault\n",
      "tensor(0.0035, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "37 tensor(0.0035, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.4497362179681659\n",
      "fault\n",
      "tensor(0.0028, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "38 tensor(0.0028, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.4825949909863994\n",
      "fault\n",
      "tensor(0.0029, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "39 tensor(0.0029, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.5155164019670337\n",
      "fault\n",
      "tensor(0.0028, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "40 tensor(0.0028, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.5486721600173041\n",
      "fault\n",
      "tensor(0.0026, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "41 tensor(0.0026, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.6068116730311885\n",
      "fault\n",
      "tensor(0.0029, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "42 tensor(0.0029, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.643581683980301\n",
      "fault\n",
      "tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "43 tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.6823008899809793\n",
      "fault\n",
      "tensor(0.0026, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "44 tensor(0.0026, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.7148520649643615\n",
      "fault\n",
      "tensor(0.0023, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "45 tensor(0.0023, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.7467140370281413\n",
      "fault\n",
      "tensor(0.0030, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "46 tensor(0.0030, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.783765131025575\n",
      "fault\n",
      "tensor(0.0019, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "47 tensor(0.0019, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.820855880039744\n",
      "fault\n",
      "tensor(0.0029, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "48 tensor(0.0029, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.8529013519873843\n",
      "fault\n",
      "tensor(0.0017, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "49 tensor(0.0017, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.8858718849951401\n",
      "fault\n",
      "tensor(0.0029, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "50 tensor(0.0029, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.9167555619496852\n",
      "fault\n",
      "tensor(0.0015, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "51 tensor(0.0015, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.946536013041623\n",
      "fault\n",
      "tensor(0.0030, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "52 tensor(0.0030, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.9764728359878063\n",
      "fault\n",
      "tensor(0.0014, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "53 tensor(0.0014, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.0114712150534615\n",
      "fault\n",
      "tensor(0.0027, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "54 tensor(0.0027, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.0462350170128047\n",
      "fault\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "55 tensor(0.0012, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.076967249973677\n",
      "fault\n",
      "tensor(0.0023, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "56 tensor(0.0023, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.108749311999418\n",
      "fault\n",
      "tensor(0.0009, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "57 tensor(0.0009, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.1407152869505808\n",
      "fault\n",
      "tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "58 tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.172160928021185\n",
      "fault\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "59 tensor(0.0010, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.2029259389964864\n",
      "fault\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0023, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "60 tensor(0.0023, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.235640782979317\n",
      "fault\n",
      "tensor(0.0015, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "61 tensor(0.0015, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.273335890029557\n",
      "fault\n",
      "tensor(0.0027, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "62 tensor(0.0027, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.305319261038676\n",
      "fault\n",
      "tensor(0.0018, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "63 tensor(0.0018, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.338630478014238\n",
      "fault\n",
      "tensor(0.0024, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "64 tensor(0.0024, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.3699286789633334\n",
      "fault\n",
      "tensor(0.0020, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "65 tensor(0.0020, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.4019893479999155\n",
      "fault\n",
      "tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "66 tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.43445254501421\n",
      "fault\n",
      "tensor(0.0018, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "67 tensor(0.0018, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.4713795869611204\n",
      "fault\n",
      "tensor(0.0020, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "68 tensor(0.0020, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.507292581954971\n",
      "fault\n",
      "tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "69 tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.541171886958182\n",
      "fault\n",
      "tensor(0.0017, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "70 tensor(0.0017, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.572731366031803\n",
      "fault\n",
      "tensor(0.0019, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "71 tensor(0.0019, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.6079434419516474\n",
      "fault\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-dffb0a94a684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents_bert_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents_ft_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mft_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-b156a4ee1b2d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, bert_input, ft_input, attn_masks)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#Feeding the input to BERT model to obtain contextualized representations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mft_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#         cont_reps, _ = self.bert_layer(bert_input, attention_mask = attn_masks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "losses = []\n",
    "for epoch in range(5000):\n",
    "    for i in range(10,11):\n",
    "        print(words[i])\n",
    "        model.zero_grad()\n",
    "        tag_scores = model.forward(sents_bert_id[i], sents_ft_id[i], masks[i])\n",
    "        y_pred = tag_scores[0].double().unsqueeze(1)\n",
    "        y_array = model.ft_embedding.source[0](torch.tensor(vocab[words[i]])).double().unsqueeze(1)\n",
    "        #print(y_pred.shape, y_array.shape)\n",
    "        loss = loss_function(y_pred, y_array)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        print(loss)\n",
    "    losses.append(loss)\n",
    "    print(epoch, loss, timeit.default_timer() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fault ['hat', 'claw', 'viper', 'welt', 'diadem', 'dagger', 'flattery', 'nether', 'flatterer', 'ruby']\n",
      "tensor(0.0017, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "eval = Evaluator()\n",
    "model.zero_grad()\n",
    "\n",
    "for i in range(10,11):\n",
    "    model.zero_grad()\n",
    "    tag_scores = model.forward(sents_bert_id[i], sents_ft_id[i], masks[i])\n",
    "    y_pred = tag_scores[0].double().unsqueeze(1)\n",
    "    y_array = model.ft_embedding.source[0](torch.tensor(vocab[words[i]])).double().unsqueeze(1)\n",
    "    #print(y_pred.shape, y_array.shape)\n",
    "    loss = loss_function(y_pred, y_array)\n",
    "    eval.top_ten_hundred(ft_dict, words[i], y_pred[i].detach().numpy())\n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
