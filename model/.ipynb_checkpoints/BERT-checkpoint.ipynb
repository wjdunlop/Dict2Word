{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "import timeit\n",
    "from scipy import spatial\n",
    "\n",
    "from evaluator import Evaluator\n",
    "from vocab import Vocab, VocabEntry\n",
    "from utils import read_corpus, pad_sents, batch_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word types: 23437, number of word types w/ frequency >= 0: 23437\n"
     ]
    }
   ],
   "source": [
    "words, defs, ft_dict = pickle.load( open( \"../data/words_defs_dict_1M.train\", \"rb\" ))\n",
    "\n",
    "vocab = VocabEntry.from_corpus(defs, 1000000, 0)\n",
    "for w in ft_dict:\n",
    "    vocab.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, src_pad_token_idx, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim, src_pad_token_idx)\n",
    "    emb_layer.weight.data.copy_(torch.from_numpy(weights_matrix)) #figure out what is here\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "class ModelEmbeddings(nn.Module): \n",
    "    \"\"\"\n",
    "    Class that converts input words to their embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_size, vocab, fasttext_dict):\n",
    "        \"\"\"\n",
    "        Init the Embedding layers.\n",
    "\n",
    "        @param embed_size (int): Embedding size (dimensionality)\n",
    "        @param vocab (VocabEntry)\n",
    "        \"\"\"\n",
    "        super(ModelEmbeddings, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        matrix_len = len(vocab)\n",
    "        weights_matrix = np.zeros((matrix_len, self.embed_size))\n",
    "        words_found = 0\n",
    "        #print(len(vocab), weights_matrix.shape)\n",
    "        for word, index in vocab.word2id.items():\n",
    "            try:\n",
    "                weights_matrix[index] = np.array(fasttext_dict[word])\n",
    "                words_found += 1\n",
    "            except KeyError:\n",
    "                weights_matrix[index] = np.random.normal(scale=0.6, size=(self.embed_size,))\n",
    "\n",
    "        # default values\n",
    "        src_pad_token_idx = vocab['<pad>']\n",
    "        self.source = create_emb_layer(weights_matrix, src_pad_token_idx, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseDictionary(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim, hidden_dim, vocab, ft_dict, freeze_bert = False):\n",
    "        super(ReverseDictionary, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        \n",
    "        self.ft_embedding = ModelEmbeddings(embed_dim, vocab, ft_dict)\n",
    "        #self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #Freeze bert layers\n",
    "#         if freeze_bert:\n",
    "#             for p in self.bert_layer.parameters():\n",
    "#                 p.requires_grad = False\n",
    "        \n",
    "        #Classification layer\n",
    "        self.lstm_fasttext = nn.LSTM(embed_dim, hidden_dim)\n",
    "        self.lin_layer = nn.Linear(hidden_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, bert_input, ft_input, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        embedded = self.ft_embedding.source[0](ft_input)\n",
    "        \n",
    "#         cont_reps, _ = self.bert_layer(bert_input, attention_mask = attn_masks)\n",
    "        \n",
    "        output, (cn, hn) = self.lstm_fasttext(embedded.unsqueeze(1))\n",
    "        \n",
    "#         cls_rep = cont_reps[:, 0]\n",
    "        \n",
    "        #print(cn.squeeze(1).shape, cls_rep.shape)\n",
    "\n",
    "        toLinear = cn.squeeze(1) # torch.cat([cls_rep, cn.squeeze(1)], 1)\n",
    "\n",
    "        #Obtaining the representation of [CLS] head\n",
    "        \n",
    "        #feed cls_rep to -> fasttext layer\n",
    "        projected = self.lin_layer(toLinear)\n",
    "\n",
    "        return projected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ReverseDictionary(300, 300, vocab, ft_dict)\n",
    "loss_function = nn.L1Loss(reduction='mean')\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sents = vocab.words2indices(defs)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_len = max(len(x) for x in int_sents)\n",
    "sents_ft_id = [torch.tensor(i, dtype=torch.long, device=\"cpu\") for i in int_sents]\n",
    "sents_bert_id = []\n",
    "masks = []\n",
    "for d in defs:\n",
    "    tokens = ['[CLS]'] + d + ['[SEP]']\n",
    "    padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [0 for _ in range(len(padded_tokens))]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids = torch.tensor(token_ids).unsqueeze(0) \n",
    "    attn_mask = torch.tensor(attn_mask).unsqueeze(0) \n",
    "    sents_bert_id.append(token_ids)\n",
    "    masks.append(attn_mask)\n",
    "assert(len(sents_bert_id) == len(masks))\n",
    "assert(len(masks) == len(sents_ft_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fault\n",
      "tensor(0.0408, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "0 tensor(0.0408, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.1167511000000161\n",
      "fault\n",
      "tensor(0.0408, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "1 tensor(0.0408, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.18973110000001725\n",
      "fault\n",
      "tensor(0.0407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "2 tensor(0.0407, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.2639163000000053\n",
      "fault\n",
      "tensor(0.0406, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "3 tensor(0.0406, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.33952469999999835\n",
      "fault\n",
      "tensor(0.0405, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "4 tensor(0.0405, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.4112983999999926\n",
      "fault\n",
      "tensor(0.0404, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "5 tensor(0.0404, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.48558479999999804\n",
      "fault\n",
      "tensor(0.0403, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "6 tensor(0.0403, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.5629172000000153\n",
      "fault\n",
      "tensor(0.0402, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "7 tensor(0.0402, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.6374332999999979\n",
      "fault\n",
      "tensor(0.0401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "8 tensor(0.0401, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.7126372000000174\n",
      "fault\n",
      "tensor(0.0401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "9 tensor(0.0401, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.7871389000000022\n",
      "fault\n",
      "tensor(0.0400, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "10 tensor(0.0400, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.8599157000000162\n",
      "fault\n",
      "tensor(0.0399, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "11 tensor(0.0399, dtype=torch.float64, grad_fn=<MeanBackward0>) 0.9351013000000137\n",
      "fault\n",
      "tensor(0.0398, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "12 tensor(0.0398, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.0126348999999948\n",
      "fault\n",
      "tensor(0.0397, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "13 tensor(0.0397, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.0904810000000111\n",
      "fault\n",
      "tensor(0.0396, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "14 tensor(0.0396, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.1715085000000158\n",
      "fault\n",
      "tensor(0.0395, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "15 tensor(0.0395, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.2450125000000014\n",
      "fault\n",
      "tensor(0.0395, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "16 tensor(0.0395, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.3232854999999972\n",
      "fault\n",
      "tensor(0.0394, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "17 tensor(0.0394, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.3977859999999964\n",
      "fault\n",
      "tensor(0.0393, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "18 tensor(0.0393, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.4720691999999929\n",
      "fault\n",
      "tensor(0.0392, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "19 tensor(0.0392, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.5449647000000084\n",
      "fault\n",
      "tensor(0.0391, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "20 tensor(0.0391, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.6154769000000044\n",
      "fault\n",
      "tensor(0.0391, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "21 tensor(0.0391, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.7022242000000176\n",
      "fault\n",
      "tensor(0.0390, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "22 tensor(0.0390, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.771805999999998\n",
      "fault\n",
      "tensor(0.0389, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "23 tensor(0.0389, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.8498089999999934\n",
      "fault\n",
      "tensor(0.0388, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "24 tensor(0.0388, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.9235112000000072\n",
      "fault\n",
      "tensor(0.0387, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "25 tensor(0.0387, dtype=torch.float64, grad_fn=<MeanBackward0>) 1.9962836999999922\n",
      "fault\n",
      "tensor(0.0387, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "26 tensor(0.0387, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.067462400000011\n",
      "fault\n",
      "tensor(0.0386, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "27 tensor(0.0386, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.149483900000007\n",
      "fault\n",
      "tensor(0.0385, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "28 tensor(0.0385, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.2196982000000105\n",
      "fault\n",
      "tensor(0.0384, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "29 tensor(0.0384, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.2949805000000083\n",
      "fault\n",
      "tensor(0.0383, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "30 tensor(0.0383, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.3713505000000055\n",
      "fault\n",
      "tensor(0.0383, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "31 tensor(0.0383, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.445591500000006\n",
      "fault\n",
      "tensor(0.0382, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "32 tensor(0.0382, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.5224077000000023\n",
      "fault\n",
      "tensor(0.0381, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "33 tensor(0.0381, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.5980308000000036\n",
      "fault\n",
      "tensor(0.0380, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "34 tensor(0.0380, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.6733837000000165\n",
      "fault\n",
      "tensor(0.0379, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "35 tensor(0.0379, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.753255600000017\n",
      "fault\n",
      "tensor(0.0379, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "36 tensor(0.0379, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.8498360000000105\n",
      "fault\n",
      "tensor(0.0378, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "37 tensor(0.0378, dtype=torch.float64, grad_fn=<MeanBackward0>) 2.938822700000003\n",
      "fault\n",
      "tensor(0.0377, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "38 tensor(0.0377, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.0263007000000073\n",
      "fault\n",
      "tensor(0.0376, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "39 tensor(0.0376, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.098420500000003\n",
      "fault\n",
      "tensor(0.0376, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "40 tensor(0.0376, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.172966300000013\n",
      "fault\n",
      "tensor(0.0375, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "41 tensor(0.0375, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.2497042999999906\n",
      "fault\n",
      "tensor(0.0374, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "42 tensor(0.0374, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.3254745000000128\n",
      "fault\n",
      "tensor(0.0373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "43 tensor(0.0373, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.396973800000012\n",
      "fault\n",
      "tensor(0.0373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "44 tensor(0.0373, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.4690650999999946\n",
      "fault\n",
      "tensor(0.0372, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "45 tensor(0.0372, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.53983869999999\n",
      "fault\n",
      "tensor(0.0371, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "46 tensor(0.0371, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.613054699999992\n",
      "fault\n",
      "tensor(0.0370, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "47 tensor(0.0370, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.685853299999991\n",
      "fault\n",
      "tensor(0.0370, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "48 tensor(0.0370, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.773557100000005\n",
      "fault\n",
      "tensor(0.0369, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "49 tensor(0.0369, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.861385299999995\n",
      "fault\n",
      "tensor(0.0368, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "50 tensor(0.0368, dtype=torch.float64, grad_fn=<MeanBackward0>) 3.949409199999991\n",
      "fault\n",
      "tensor(0.0367, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "51 tensor(0.0367, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.036486700000012\n",
      "fault\n",
      "tensor(0.0366, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "52 tensor(0.0366, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.123343800000015\n",
      "fault\n",
      "tensor(0.0366, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "53 tensor(0.0366, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.208874500000007\n",
      "fault\n",
      "tensor(0.0365, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "54 tensor(0.0365, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.296141900000009\n",
      "fault\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0364, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "55 tensor(0.0364, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.37024679999999\n",
      "fault\n",
      "tensor(0.0364, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "56 tensor(0.0364, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.444668500000006\n",
      "fault\n",
      "tensor(0.0363, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "57 tensor(0.0363, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.516454199999998\n",
      "fault\n",
      "tensor(0.0362, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "58 tensor(0.0362, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.5908223000000135\n",
      "fault\n",
      "tensor(0.0361, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "59 tensor(0.0361, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.668869999999998\n",
      "fault\n",
      "tensor(0.0360, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "60 tensor(0.0360, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.742874900000004\n",
      "fault\n",
      "tensor(0.0360, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "61 tensor(0.0360, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.818586900000014\n",
      "fault\n",
      "tensor(0.0359, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "62 tensor(0.0359, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.893990800000012\n",
      "fault\n",
      "tensor(0.0358, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "63 tensor(0.0358, dtype=torch.float64, grad_fn=<MeanBackward0>) 4.967619900000017\n",
      "fault\n",
      "tensor(0.0358, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "64 tensor(0.0358, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.041759000000013\n",
      "fault\n",
      "tensor(0.0357, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "65 tensor(0.0357, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.117559400000005\n",
      "fault\n",
      "tensor(0.0356, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "66 tensor(0.0356, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.192301000000015\n",
      "fault\n",
      "tensor(0.0355, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "67 tensor(0.0355, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.266049400000014\n",
      "fault\n",
      "tensor(0.0355, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "68 tensor(0.0355, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.340958999999998\n",
      "fault\n",
      "tensor(0.0354, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "69 tensor(0.0354, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.425254999999993\n",
      "fault\n",
      "tensor(0.0353, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "70 tensor(0.0353, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.526996099999991\n",
      "fault\n",
      "tensor(0.0352, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "71 tensor(0.0352, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.618136899999996\n",
      "fault\n",
      "tensor(0.0352, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "72 tensor(0.0352, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.706361000000015\n",
      "fault\n",
      "tensor(0.0351, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "73 tensor(0.0351, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.783484000000016\n",
      "fault\n",
      "tensor(0.0350, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "74 tensor(0.0350, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.862601100000006\n",
      "fault\n",
      "tensor(0.0350, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "75 tensor(0.0350, dtype=torch.float64, grad_fn=<MeanBackward0>) 5.9373218000000065\n",
      "fault\n",
      "tensor(0.0349, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "76 tensor(0.0349, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.0096822000000145\n",
      "fault\n",
      "tensor(0.0348, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "77 tensor(0.0348, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.083892800000001\n",
      "fault\n",
      "tensor(0.0347, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "78 tensor(0.0347, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.158715000000001\n",
      "fault\n",
      "tensor(0.0347, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "79 tensor(0.0347, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.233983100000017\n",
      "fault\n",
      "tensor(0.0346, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "80 tensor(0.0346, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.307708700000006\n",
      "fault\n",
      "tensor(0.0345, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "81 tensor(0.0345, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.383230300000008\n",
      "fault\n",
      "tensor(0.0344, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "82 tensor(0.0344, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.456917000000004\n",
      "fault\n",
      "tensor(0.0344, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "83 tensor(0.0344, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.532728700000007\n",
      "fault\n",
      "tensor(0.0343, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "84 tensor(0.0343, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.608309899999995\n",
      "fault\n",
      "tensor(0.0342, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "85 tensor(0.0342, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.678851299999991\n",
      "fault\n",
      "tensor(0.0342, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "86 tensor(0.0342, dtype=torch.float64, grad_fn=<MeanBackward0>) 6.75906950000001\n",
      "fault\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-dffb0a94a684>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\torch\\optim\\adagrad.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mclr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "losses = []\n",
    "for epoch in range(5000):\n",
    "    for i in range(10,11):\n",
    "        print(words[i])\n",
    "        model.zero_grad()\n",
    "        tag_scores = model.forward(sents_bert_id[i], sents_ft_id[i], masks[i])\n",
    "        y_pred = tag_scores[0].double().unsqueeze(1)\n",
    "        y_array = model.ft_embedding.source[0](torch.tensor(vocab[words[i]])).double().unsqueeze(1)\n",
    "        #print(y_pred.shape, y_array.shape)\n",
    "        loss = loss_function(y_pred, y_array)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        print(loss)\n",
    "    losses.append(loss)\n",
    "    print(epoch, loss, timeit.default_timer() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.spatial.distance' has no attribute 'coside'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3a574c009836>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#eval.top_ten_hundred(ft_dict, words[i], y_pred[i].detach().numpy())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoside\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'noon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoside\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fault'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.spatial.distance' has no attribute 'coside'"
     ]
    }
   ],
   "source": [
    "eval = Evaluator()\n",
    "model.zero_grad()\n",
    "\n",
    "for i in range(10,11):\n",
    "    model.zero_grad()\n",
    "    tag_scores = model.forward(sents_bert_id[i], sents_ft_id[i], masks[i])\n",
    "    y_pred = tag_scores[0].double()#.unsqueeze(1)\n",
    "    #print(y_pred)\n",
    "    y_array = model.ft_embedding.source[0](torch.tensor(vocab[words[i]])).double().unsqueeze(1)\n",
    "    #print(y_array)\n",
    "    #print(y_pred.shape, y_array.shape)\n",
    "    loss = loss_function(y_pred, y_array)\n",
    "    #eval.top_ten_hundred(ft_dict, words[i], y_pred[i].detach().numpy())\n",
    "    print(spatial.distance.cosine(ft_dict['noon'],y_pred[i].detach().numpy()))\n",
    "    print(spatial.distance.cosine(ft_dict['fault'],y_pred[i].detach().numpy()))\n",
    "    print(sorted(ft_dict.keys(), key=lambda word: spatial.distance.cosine(ft_dict[word], y_pred[i].detach().numpy())))[:10]\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
