{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yuloucn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#from model_embeddings import ModelEmbeddings\n",
    "from evaluator import Evaluator\n",
    "from vocab import Vocab, VocabEntry\n",
    "from utils import read_corpus, pad_sents\n",
    "Hypothesis = namedtuple('Hypothesis', ['value', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = []\n",
    "unparsed_definition = []\n",
    "words = []\n",
    "src_sents = read_corpus('../data/data_train_definitions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data_train_words.txt') as f:\n",
    "    words += f.read().splitlines()\n",
    "    \n",
    "with open('../data/data_train_definitions.txt') as f:\n",
    "    unparsed_definition += f.read().splitlines()\n",
    "    definitions += [word_tokenize(a) for a in unparsed_definition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(words) == len(definitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word types: 23452, number of word types w/ frequency >= 0: 23452\n"
     ]
    }
   ],
   "source": [
    "eval = Evaluator()\n",
    "glove_dict = eval.load_glove_embeddings(max_line = 50000)\n",
    "\n",
    "src_sents = read_corpus('../data/data_train_definitions.txt')\n",
    "vocab = VocabEntry.from_corpus(src_sents, 30000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, src_pad_token_idx, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim, src_pad_token_idx)\n",
    "    emb_layer.weight.data.copy_(torch.from_numpy(weights_matrix)) #figure out what is here\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "class ModelEmbeddings(nn.Module): \n",
    "    \"\"\"\n",
    "    Class that converts input words to their embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_size, vocab, glove_dict):\n",
    "        \"\"\"\n",
    "        Init the Embedding layers.\n",
    "\n",
    "        @param embed_size (int): Embedding size (dimensionality)\n",
    "        @param vocab (VocabEntry)\n",
    "        \"\"\"\n",
    "        super(ModelEmbeddings, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        matrix_len = len(vocab)\n",
    "        weights_matrix = np.zeros((matrix_len, self.embed_size))\n",
    "        words_found = 0\n",
    "        #print(len(vocab), weights_matrix.shape)\n",
    "        for word, index in vocab.word2id.items():\n",
    "            try:\n",
    "                weights_matrix[index] = np.array(glove_dict[word])\n",
    "                words_found += 1\n",
    "            except KeyError:\n",
    "                weights_matrix[index] = np.random.normal(scale=0.6, size=(self.embed_size,))\n",
    "\n",
    "        # default values\n",
    "        src_pad_token_idx = vocab['<pad>']\n",
    "        self.source = create_emb_layer(weights_matrix, src_pad_token_idx, True)\n",
    "        ### END YOUR CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, vocab, glove_dict):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = ModelEmbeddings(input_size, vocab, glove_dict)\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.hidden_size, bias = False)\n",
    "\n",
    "    def forward(self, input_, hidden):\n",
    "        embedded = self.embedding.source[0](input_)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        projected = self.linear(hidden.permute(1,0,2))\n",
    "        return projected, hidden\n",
    "\n",
    "    def initHidden(self, device = None):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderRNN(50, 50, vocab, glove_dict)\n",
    "loss_function = nn.SmoothL1Loss(reduction = \"sum\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(7.1949, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "100 tensor(6.1411, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "200 tensor(6.0707, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "300 tensor(6.7015, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "400 tensor(6.7902, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "500 tensor(6.0770, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "600 tensor(6.0715, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "700 tensor(6.6887, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "800 tensor(6.3561, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "900 tensor(6.7868, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1000 tensor(6.7812, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1100 tensor(6.7899, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1200 tensor(6.7870, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1300 tensor(6.7891, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1400 tensor(6.7898, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1500 tensor(6.7932, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1600 tensor(6.7890, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1700 tensor(6.7916, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1800 tensor(6.7923, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n",
      "1900 tensor(6.7914, dtype=torch.float64, grad_fn=<SmoothL1LossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f3ab2bc9e7fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "definition_indices = vocab.words2indices(definitions)\n",
    "words_in = 0\n",
    "words_out = 0\n",
    "\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "losses = []\n",
    "for epoch in range(6000):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for i in range(1600): #should be range(len(definition_indices))\n",
    "        if words[i] not in glove_dict: \n",
    "            continue\n",
    "        model.zero_grad()\n",
    "        x = torch.tensor(definition_indices[i])\n",
    "\n",
    "        init_hidden = model.initHidden()\n",
    "        tag_scores = model.forward(x.view(x.shape[0], 1), init_hidden)\n",
    "        y_array = np.array(glove_dict[words[i]]) if words[i] in glove_dict else np.random.normal(scale=0.6, size=(50,))\n",
    "        y = torch.tensor(y_array).double()\n",
    "        y_pred = tag_scores[0].view((tag_scores[0].shape[2])).double()\n",
    "\n",
    "        loss = loss_function(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss)\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, loss)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<matplotlib.lines.Line2D object at 0x1a392b13c8>]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xt8FNX5P/DPs7tJSICQAOEaINwRVEQighS1XhCEalsvpWq99kttbb31hrXlZ61ttb5qW7WVL9V+1aqt1XqteLfeBQ13FFBAlHANIAQIkGT3+f2xs5vNXmc2M7s7u5/365VXdmfPzDw72Txz9syZc0RVQURE+c+T7QCIiCgzmPCJiAoEEz4RUYFgwiciKhBM+EREBYIJn4ioQDDhExEVCCZ8IqICwYRPRFQgfNnacc+ePbWmpiZbuycicqXFixfvVNWqdNbNWsKvqalBXV1dtnZPRORKIvJZuuuySYeIqEAw4RMRFQgmfCKiAsGET0RUIJjwiYgKBBM+EVGBYMInIioQKRO+iIwUkWURP40icm1UmZNFZG9EmbnOhQws3LAL63bsd3IXRER5J+WNV6q6FsAxACAiXgCbATwZp+hbqjrT3vDimzV/IQBg460zMrE7IqK8YLVJ51QA61U17Tu9iIgoO6wm/FkA/pHgtUkislxEnheRMR2Mi4iIbGY64YtIMYCzADwW5+UlAAap6lgAdwF4KsE2ZotInYjUNTQ0pBMvERGlyUoNfzqAJaq6PfoFVW1U1f3G4wUAikSkZ5xy81W1VlVrq6rSGuyNiIjSZCXhfxMJmnNEpI+IiPF4grHdXR0Pj4iI7GJqeGQRKQNwOoDvRCy7EgBUdR6AcwF8V0RaARwEMEtV1f5wiYgoXaYSvqo2AegRtWxexOO7Adxtb2hERGQn3mlLRFQgmPAjzHtjPWrmPIem5tZsh0JEZDsm/Aj3v7MRALCnqSW7gRAROYAJP4IieJ052N+IiCi/uC7hH2z2O7btUL8iATM+EeUf1yX8BSu3OrbtUD9S1vCJKB+5LuE3+wOO7yOX8/3Pn1qJmjnPZTsMInIh9yX81raE//YnO23dthtuFXto4efZDoGIXMrVCf+i+xbZvPVwIz4RUd5xX8J3sEmHF22JKJ+5LuEfbnUw4Ru/edGWiPKR6xL+hJrujm07NN4b8z0R5SPXJfxe5SWObbuths+UT0T5x3UJn4iI0uO6hO9k3dsN3TKJiNLluoTvJM7ZQkT5jAk/Qijd2534VRWtDnQn3dvUAn+AJykiMidlwheRkSKyLOKnUUSujSojInKniKwTkRUicqxTATt6PdVC7mzxB3DP6+txuDX5YG4N+w5j8A0LMOzG5zsYXHuHW/0Ye/NL+MXTq0yVP+eed/Hjx5bbGgMRuUvKhK+qa1X1GFU9BsB4AE0AnowqNh3AcONnNoB77A40k8zk/YcWfobbXliDv765IWm5O1/9pG27Fr45NLcGMPOut7BwQ/y54A+1BL8xPLtsi6ntLf7sCzy2uD78/J11O7GX4/4TFRSrTTqnAlivqp9FLT8bwIMatBBAhYj0tSXCGM5V8a00jjQZwzQfSDFcc+Q3ErP5vmbOc7ju0WVYtbkRNz65Mn6hcB9Sc9uMdOBwKy68dxGueOAD6ysTkWtZTfizAPwjzvL+ADZFPK83lrUjIrNFpE5E6hoaGizu2nkBhy/aWtn6c8Yw0InWUUtba89vvM+12/alvQ0ich/TCV9EigGcBeCxeC/HWRaTkVR1vqrWqmptVVWV+SgzzEret1LBtvNicKAD47yF1nH6BEdEucVKDX86gCWquj3Oa/UABkQ8rwZgrnHZIicv2lrJf+kkbzvTayhZp3NXcGgdpnuiwmIl4X8T8ZtzAOAZABcbvXUmAtirqs5NTeWQUDOJleaSVPnWSjretLsJR9/0oqmydlTOWcMnKiw+M4VEpAzA6QC+E7HsSgBQ1XkAFgA4E8A6BHvxXGZ7pA764kAz1m7fZ7GGb30/0eu8u34ntjcewtfGVQMAnl62GY2HWk1t69XV8b5oWcMu/ESFxVTCV9UmAD2ils2LeKwArrI3tPicaNG56L5F+HBLI4q8aTSPWIgo+pvDBX8NTuASSvhWzHki2HsnnSauUHMU7ywmKiy80xbAR1sbAUTUeE3kQbOpMrKNvaP59dx73u3YBkJxhH4z3xMVFCb8COkOU3Dr82vw0ZZGm6OJVffZFzHL0vnGE0r0zPdEhcV1Cd+Jseqja7pWEuGB5lbMe2M9zv/f9yzvJ+TJpcE7YDvS48YSIw5etCUqLK5L+LlgR+Mh3PHyx+2WmWkPT9T757pHl5vehh3CvZGY74kKiqmLtrkkE3NRpUqEr6ze4ch246+U/OVcnJtr295DqCgrQqciLzbuPIDSYi96l3cyvX7DvsPwBxR9uqVeR1Vx+4tr8bVx/TGwRxkeeHcjfvfCWjz+3RPw0MLPMG1MH9R/0YSNu5rwyKLP8duvH4VfL1iNbqVFGDewAu+t34VinwcHm/0o8nrQqciD9Q0HwtsvK/bioW8fj1dXb8ef/7seA7qXoqpLCZZ8vidcpmsnH/ZF9a4qLfICAA62xB96o3d5CbY3Hg4/nzK8JxoPtmB5/V7TxwkAvB4JN0VGbzNS326dsHXvoZjl/StK0RoIYHvjYQzr1QU+j8AjgiKfB1CF1yPh9zq8VxfsO9SKbY2HUOLzhOeXrigrwh5jXKahVZ0hIli3Y394Hz27FKNLiQ+dirwo8nqwcnPwPY4dUIFAQMPPQwZ2L4PPK9gQ8XfoX1EKVUWRz4NDLf7w+zyuphIBBfY0NaNziQ8BVXg9HrT6A9jT1IKKsiKIBDtXeARYXr8XlWVFqOpaAq/HA59HoAiuk45AQOHxCLqUeNHU7EeJz4NinxfFXsGephY0NftR5BW0BhS79jejqmsJWvwBnFc7AFd8aXBa++wI1yX8bGk81IK/v/cZvnvSUBw43PbPnaiXTiCgaI26JpAq3ydrnnltTce7YYbjcLBm3+oPYOJvX8UZY3rj2tNGYPqf3gIAfOekIbhh+hHhck8v24zVW/dhzvRRMds47tevAACuO20EZk0YED5ZHDjcCgXQpaTtY7v7QDP+8vp6/OX19e228dU/vwMAeDxiwDgA+KExYujuA834dOcBpNLU7MfX/9J2sXzT7oPYtPtguzLRyR5InOhDohPz57ub8NmuppTxRIu87pQo2QPAtsbYZA8EpwxdaiT0oVWdEdDg56OpuRUfb9+PbqVtx7pTkRefGIk8lOwBoE95JzS3BtClxIdRfcpxoLm1XcIf3a8bio0ecI0HW1HkFVSWFcPnESytbztxhgzoXooir6ddwvd5BRWlxQhocGDBSM2tAXQu8aHY64HHI2jxB5/Xf3EQQ42TmKoioEBlWREGdC9Dv26l8KvCH1C0+APwpNlU7A8omv0B7DvUioAqijwe7D3YgsMtfvi8gvJSH0p8XrT4Aygt8qK8tAhej6CyrCit/XUUE74Jqorz7nkPa7fvw8jeXXGgOSLhJ/ic/PLZD/HAe5/h0hNqwsvueOljFHkFc6aPiknuOxL8Q4Zcfn9d2vFHM5PvX129HZOH9UQno6Zq1vZ9waTz4ofb8eKHbSep/31jA84bPwDDenUBAFzzz2UAEE74e5qa8bMnV+JXZx8ZXucPr3yMP7zyMe765jh8ZWw/jLv5ZTT7A1h7yzR4RHDvW5/ithfWWIrPrPNrq/GvuvrUBQ19yju1S6rzLjoW047si1Z/AIdbA1i5eS8uv/8DNDX7cfnkwfjxGSPx0dZGHDOgAl5P8LOwemsjrnpkCb41cRB++exHeOPHJ6O6sgyLNuzCwB5lONjsx+l/eBMA8I3aAXi0blNMHO/OOQWrtzbiyyN7weMR7Nx/GC9+uA0XTBgIkWAy9IpgyM8W4MYzj8D/nDgk5Xt7eNFnWL21Ebd89Sjc/OxH+Ns7n+LjW6aj2R+AzyNxPyOrNu/FzLvexqzjBuDWc45Ouv3New6iyCvo1bX9N7qXPtwGf0BR2bkYE4f0iFlPVS1fw0pnnXziuoSfib9VdFv7Xa+tw9rtwYHGWvyBdjX8RP6+MDigaGS7/N/e+RQAcOnkGvTtVtqu/ITfvIofnzHScqxWj4eqprxWsGzTHlzxQB0uPH4gfv21oyxt/2CS0UNPu+MNbLx1Rrtloa/Ejy+ux4KV22KOCwD84B9L8ZWx/dBsTCIz8ucvoF+3TtgSp4nCDlefMgzXTx2J3507Ft+6bxHe+mRnTJmhVZ3x6HcmwR9Q1H/RhPGDuuP3L61F5xIfrjxpaLicz+uBz+vBxCE98NHN09ptY/ygynbPj+hbjtd+eDIA4LLJbV/3TxjWM/x45U1T0bVTEVQVj9Ztwo+mjsDZx/THT/+9ApdNHox+FaXoV9F2DHt2KcGFxw8KPy/yBpsuov8OyUSuf+OMI3D91BEo9nlQ7EvcDHJk/254+boTMbBHWcrt96+I/ZsDwNQxfZKul7FODnnEdQk/095dt7PdBdrvPrwEFxw/MKZc9AdJRACNbdYBgFa/fW0qO/c3WyqvmrqGv/dgsD32893WmhiaWwP41n2LLK3jV4UHgvJOwa+4e0yO0W9nsn/rJ1/GlN/9N/y8tDj+v0XXEh/2GSf73379aPTsUgIA4SanH061fsK2qqtxnESkXdJ+5H8mOr5vIHjNILJJLZnhvbs6HA1Z5fpeOgcOt6LxUPoTeazeGtt/PrICHO8iWvs2/NA67dOo8S09btfH7z682HR8dje3K+K34T+5tB6Db3gOh1v9Ee/J2rbX7dgf98JgpLte/STcRg+0tUGHjpPPE78GFtkmbLcB3dvXQv2BtjbiQxFt8SLAy9ediBeunYIJg7s7Fg+RU1yX8KMvkk749Ss4+qaX0t5e6KJiPC3+AG5/MbaNOLKGfp/RTBMtVOOPdzPXqs323qRVM+c5PLHEXHtzQDVu99Cbn/0IqsGZsMx86/UHNOa9mRl07vcvf4yGfW0XF0OJPjRUhDfB8Ban3fFG6qA64CfT2mrn045sm7vng41tN7t5PILhvbtiVJ9yR2MhcorrEn60VDNOpWOT0ZSxYOXWlAOMhWrBMU06xu94TTpOeGLJ5rjLX129vd1dwNG19n2HWvCt+xbhC6Mp5ZfPftRWNk4C/3xXE1Zt3ovxt7yMEyOaQV5bsx0z7nzbctzRxydRDd8OvctLwo9H9Qk2N9x89hgAwPdOHoaNt87AxltnhC8sRyvs1l/KB2zDj+Mb8xdi460z2n2dTyW2SSeYHgIWEn66QzvEU3vLyygt9sZ0IVS0b8RfsHJru4uSXxvXP+mAcCfe3pbkI9vb73x1XVpxRh8fr4MJ/4wxffDIos8xZ/oonH/cAKzZui9l08wvZo7Gr/4TPAmm23WPKFe4LuFn8n+uI7XzUN6yso2d+xP3o7Yq0cXc6Iu20TX+Hp2LE76WzH4TPZfiiT7JWb0IbYUqsO43Z4afm2mHv+JLg3HSiCqcdscbBd/Dg9zP9U06TkpUO393fWw3vehkEK7hJ8iaHbnQHI/ZXKSaPJFr1Lau/edSDPvZgtT7N7f7GH7VdieLZ5c7MlEagPTnAQ41MxWnMXw2US5hwk8iUe38CxNdB0NJMxCI//r0Pya+WJyOtz7ZiRZ/gp1FUMS/aBsy9+kPwxdVVYGnlm1Bq3GB9vL7P0i4XrrNHYEAcEWS7dop3TuMQ6sVJel3TuQGpj7BIlIhIo+LyBoRWS0ik6JeP1lE9orIMuNnrjPhZlZH6nOhGn+ik8bmPQdjlnW0/njnq5+kLKMKTPrta23P45RZbAzDHHli+NMrH+O1NYnHEEq3taM1EMCiT3entW7owqtZ6TbQhW7lL/Yy4ZO7mW3D/xOAF1T1XBEpBhDv9rm3VHWmfaFln5ULiIn64fsTVfFN+nTnAfzt7fhdP6NtM3EzkpmkF0pwkW9pxebkg3ql274dCACdijw41GL9OFn9VjFuQIXlfQBA55Lg0AG1NZUpShLltpQJX0TKAZwI4FIAUNVmAM5dWUsZTyb3ZX5n0d1DQ8nIjptqb/7PR6kLwdyxMTMG/qHW2N5Jr69tiFt27tOrMHfmaKTbucavihKfN72Eb7LCPaZfOeZdNB7VlfFv4U+lurIMz3x/Mvvfk+uZ+ZcZAqABwP+JyFIRuVdEOscpN0lElovI8yIyxt4w07e+YT/qNlpvMti5/3Bac9yGtLXhZ27QeTPz62pUXv1wS2zN3UrID773Gd78pKFDow0WpdlU4rWwzwHdyzrUy+bo6oqkY8cQuYGZT7APwLEA7lHVcQAOAJgTVWYJgEGqOhbAXQCeirchEZktInUiUtfQEL/GaLdTf/8Gzp0XOxuVP6C4K0mb963Pr7GU+KKFksvb62J79KRaJ/19pi7jj6rhP7Tw85gy4UnOTe738vvr0h76YE9Tc9rf2hIdr5qoAbvSPaEQ5Rsz/wn1AOpVNTQq1uMIngDCVLVRVfcbjxcAKBKRnoiiqvNVtVZVa6uqqtIK2K6+0C9+uA2/j5q1KpJXJO0boZ5bsbXd8AGZYubQtJq4phB61+9buJiaavz3RM6d917ax8rrEZxfWx2z/LrTR4Qnl7jqy0Px5wuPjSlDVIhStuGr6jYR2SQiI1V1LYBTAbRrVBaRPgC2q6qKyAQETyS7HInYJqnuovV5Je05X696ZEla63Vc6oxv5iTmt3E0Tyd5BPjduWOxon4v1mzbF15e5PXgFzNH4xczR2cxOqLcY/a77g8APCwiKwAcA+A3InKliFxpvH4ugFUishzAnQBmaaYmaHVIkdcTM7OO0/4VZ0ILK8wOepZKs4n+/LkgdN3gnovGt1vu5Hg8RG5mqlumqi4DUBu1eF7E63cDuNvGuBKy61851emoyCu45bnVlrfb2oFk2dTBgeDM5DkzvUQzfaJLVyjhD+7ZGd1Ki8Lj+PeyMH8uUSEp2KtZqeq5vjQv9G3clXqeVKeY6aUTfdE2HrfU8OPdJ/GVsf1wTJr97YnynesSvl398P+7NvFdowCw3aHp85xkrkkndTJ3TQ0/IuGH3vvNZ+VMj2CinOO6hJ9IaDgAs55bsTXp608sjT++fC4zcy40U3lftmlPh2Nx0ph+wRug2FRPZE3eJPxz7nk32yFknYhgfcP+pEMVf5DGTWi5JjSpduTF2VnHBecZLi32ZiUmIjdwXcI3005dyE79/Ru45G/vJ3z950+tymA0HffGj09u9/z/Lj0OlWXBibx9EWMr/HTaSKy9ZRo6FTHhEyXiuoRPiYXasa02bznlq8f0w8ZbZ7Rb9p0Th5ha9xczR+PpqyZjUI/OWHD1FNQOCg5cNqB7aXgEUm+7NnxBiY/JnigZ1814lfuy9w0k19re442vM7qfuQHILjuhJnxRdnS/cjx25SRs2XsI/StKw5PAOzkdIlE+cl0Nn7PMJbb089xK+PGGwTA7XEX0qiKC/hXB0S5DNXwfZ6AissR1CZ/cI14F3Owcv8nGTAp1LbUyWiYRFWjCv/5fyxzZrqpin81z1brZuIHBdvefzzgivGxoVZcOb3dg9+Do3GN5gxWRJa5rw7ejTvfEEmf62D9WV4+f/HuFI9t2g5G9u2Lt9uAgZv/90cnhYYq/PWUIvj1lCLbuPYi+3dKbhCTSpKE98NJ1J2J4r46fPIgKSUHW8J1SyMkeAH5w6rDw48E9O8c0y9iR7ENG9O5q21DZRIWi4BL+s8u3ZDuEvMV7JIhym/sSvoWc8ubHsbNq/eAfS20MhiKJAO/MOQUrbpqatNy8i2InJHnk28fjlFG9nAqNiODGhG/BxUnuOI02oaa7g5EUBgHQv6IU5Z2KkpYLXXQNWfOraThhWE9UlCZfj4g6xnUJP91mg/vf+RQPvrcx2YZxVP9uaW3bzSYP62Hbtsy2qUfeMDXvovHh4RDYJk/kLFMJX0QqRORxEVkjIqtFZFLU6yIid4rIOhFZISI5N4noTc9+hLlPf5jwdQEw2+Rt//nkT7PGpbVevNxsNl+3GEN2jurTFdOO7BNefskJg9KKhYjMMVvD/xOAF1R1FICxAKKngpoOYLjxMxvAPbZFmCFH9e+W13fxjurTNe7yVM0viZT4Yj86Zg/fvkPB0TzLo5pwCvEbFlEmpUz4IlIO4EQA9wGAqjaravQ9/GcDeFCDFgKoEJG+tkcLZ4ZWOGFoD/x0+ij7N5xD+nRrm/ZvSM9gG/q9F9eiOE7iBoDffv2opNu7eFJNzDKzTTKhk8/VpwyPu343tuUTOcLMjVdDADQA+D8RGQtgMYBrVDVyLr/+ACJn4K43liWfZSRHHFXdDUVpTmnoFqGBzKorS/HqD0/C1r2H0M8Ym+aYARUxA6+lSt1zpo3C/Dc3WFonpLJzccwomiF/+MZYjB/IC+hETjCT5XwAjgVwj6qOA3AAwJyoMvH+12MGTRGR2SJSJyJ1DQ2xXSazLZ/7kYfemWqwJh1K9kDbgGZdStrO/2eM6YNkPHEGyvHYcM782rhqDDTu0CUie5n5F60HUK+qi4znjyN4AoguMyDieTWAmDucVHW+qtaqam1VVVU68TqSkvuWd0pdyOXiJeiQG6aPQv+KUnxw42nhZZWdiy3vI59PmET5IGXCV9VtADaJyEhj0akAPooq9gyAi43eOhMB7FVVVzTnAG3t0fl80fbKk4YCAAIaO1rlCcN64p05p5ieHnDeReNtjY2IMsPs4Gk/APCwiBQD2ADgMhG5EgBUdR6ABQDOBLAOQBOAyxyI1THJar/5IjQtYLyEb9WYBJOYaGwrHhHlEFMJX1WXAaiNWjwv4nUFcJWNcSXk5M05+Zz2QxelTQ5Hn1SiP4ExTD0R5aj87ppig3xp5gnNDmVDBT/u1IWAPd8eiMg5BTkevhX3XlyL6soynPHHNzO8Z3v5jC40miIpv3L9iWhuTV4mUcJnuifKba5L+E6Kl8d6l3fCyAR3qbrFk987ITx+Tapa+LBeqd9rokseqU4mRJRdbNJJIVFt1k36VZSGvxnZ04Yf3FrPLiUAgGlGn307tk1EznFdwnc2/zpzM1G2eT2CzsZNVVYHiDtjTO+YZaG/wVNXnYC7LxgXfs4KPlFuY5NOCvlQwy/yeFDs8yQcziCRUPl31+1Ew/7DuPnZj7DrQHP49erKMlRXluH5ldsAsFsmUa7Lg/qrs7LRRb+qa4mt2/N6O/YmThjWE2cf0z/h66FzIpt0iHKb6xK+k7fvxx/jPfMZv8bmsWR8Np+1optuQt+CeNGWKLe5LuFnmjcLCd/u4YG9NiX8RIfCE67hM+ET5TIm/Ajx8ll22vDt3addJ60fTg0Op1Re2v7ST+hbEO+0Jcpt7rtom+H864ZrttWVpaj/4mC7ZStvmoqln+/Bo3WbbBsr6JsTBuKbEwbGLA/30rFlL0TkFNbwU8jOwGrWUueMo/qGZ7EK8YjgxBFV+PMFzk8vHPoWxCYdotzmuoTvZI073gXa0JK7L0hvsu90RM/1aoYvqieOXe32ZnjC/fCZ8IlymesSfqZlo8vhL88aY6pcZPdNb9QdYplsimqr4Wdun0RkHRN+hLjzNBpJLBCRzcwm5HR17WSuhh++GCux9wtksndRWXHwUpDd3T+JyF6uS/jZSinDe3cBANx+7tG45IQay+u//7NTsfz/TcVFE2MveqYrstmmdlBlu9cy2bvoh1NH4OpTh+Or4xLfnEVE2ee6hO+kZC0SY/p1w5JfnI7zagckKZVYr/JO6FZahFu+elS7IQ76R0wmbkV5Jx9OH902zs3PZ45u93omLzZ3LvHh+tNHhCdZIaLcZOo/VEQ2ishKEVkmInVxXj9ZRPYary8Tkbn2h2qN2QuII3u3DQecap3uaUzsncplk2tMlTuib/tpBVfcdAZ6lQfb8AXSLtnee3H05GRERNb64X9ZVXcmef0tVZ3Z0YBSMTvUwbw3Npgq9/D/HB9+nMsXHZ+/Zgpq5jyXtIzXI7h40iCcNjp2hEsiIvfdeGXSSx9tS1lmwuDu4THdgfg1fDO1+inDe+KtT2LPhaP6dMWabfuSrtuRvuvRq67/zZlpb4uI8p/ZRlcF8JKILBaR2QnKTBKR5SLyvIjE7cYiIrNFpE5E6hoaGtIK2E6jo5pJImv4RV7BxltnoFORN+V2EuXsZCNMplo3mSP7t4/bDXcDE1H2ma3hT1bVLSLSC8DLIrJGVSMneV0CYJCq7heRMwE8BWB49EZUdT6A+QBQW1ubVtXWztz2szOPaPc8srZtZVTOROPAm6m9WzkIVsezJyKKZKqGr6pbjN87ADwJYELU642qut94vABAkYj0tDlWWx3RtxzFvvZvv12C7uCZpaZHGboYs0x9a+KghOXsuDmVFXwiMiNlwheRziLSNfQYwFQAq6LK9BHjaqqITDC2u8v+cO1rvqj/oin5ftLc7mlH9AIATD+qLw63+gEAJb7Eh5mzRBFRppip4fcG8LaILAfwPoDnVPUFEblSRK40ypwLYJVR5k4AszTLA6ukStiHWvwxyyJvZLJyYol8pzedNQbdOxfjG7UDMG1MX3gEOP+4xH33O3KUOHYNEVmRsg1fVTcAGBtn+byIx3cDuNve0NLT4g+gxZ96YPYWf2yyjByO4Mwj+yZdv3d5CbY3HgYAzP3KaEz741sAgvO8LvnF6eFyG34bv929urIU5xxbHbP89nOPThl7yIXHD8KiT3fj8i8NNr0OERUu190amepi6oV/XYTRc19Ma9uhGv7YARW4LUXife7qKeHHo/qUJykZ39s/PQXXnT4C1ZVtd9pOGd7T0p28lZ2L8fcrjm/XtZSIKBHXJfxU3t+4G0B6k3GEEn73sqKUwwTYlWTPGtsP3zlpiC3bIiJKJu8SfkeEEn5rBm+5FRFMHprTHZqIKE/kbcJf+vkey+uEEn46d7+O6tM1daEUInc7dkBFh7dHRBQpb4dWSMdgY5rA04+wPhbNk9+bjKbm1rT2G69H0OShPbB8k/WTFhFRIkz4Eaory7DypqnhG6ZSef6aKeFx50uLvSgtTj0Mg1kcLoGI7MaEH8XsbFNA7JDF6erVtRMA4OjqbuFlVoZ2ICIygwk/B4zs0xULrp6CEcasWgBr+ERLg8cbAAANNElEQVRkPyb8HDG6nz3fFoiIEsnbXjpuxwo+EdmNNfxcZbTpnD66N26MGsaZiCgdrqvhJ2vb3n2gOXOBOCz0No/oW44ao7soEVFHuC7hJ/PEkvpsh2AbXrQlIrvlVcL3mxwSoazYi1euP8nhaGzCIZCJyCb5lfBNJsfTR/fGsF5dUhfMolA/fKZ7IrJLXiX8gMkafr+K0tSFsizUpMMKPhHZxVQvHRHZCGAfAD+AVlWtjXpdAPwJwJkAmgBcqqpL7A01KHLYYq9H2jXjmBnl8i8XHovT0hgrJ9NCTficApGI7GKlhv9lVT0mOtkbpgMYbvzMBnCPHcHF024awqjXzNTwpx/ZJ2by8lx08sjg3LinjMr9kxMRuYNd/fDPBvCgMY/tQhGpEJG+qrrVpu3HFd2TxUwbvrik+8tR1d2w8db40yMSEaXDbFVXAbwkIotFZHac1/sD2BTxvN5Y5qjoAcYyOXEJEZHbmK3hT1bVLSLSC8DLIrJGVd+MeD1etTkm+xoni9kAMHDgQMvBpmL2oi0RUSEyVcNX1S3G7x0AngQwIapIPYDI2berAWyJs535qlqrqrVVVVXpRRwp6jTz17c+7fg2iYjyVMqELyKdRaRr6DGAqQBWRRV7BsDFEjQRwF6n2++JiMgaM006vQE8aVzs9AF4RFVfEJErAUBV5wFYgGCXzHUIdsu8zJlwiYgoXSkTvqpuADA2zvJ5EY8VwFX2hkZERHbK/Q7pyfAaLRGRae5O+EREZBoTPhFRgWDCJyIqEEz4REQFggmfiKhAMOETERUIJnwiogLhyoTfudib7RCIiFzHlQn/jZ98GY9dOSnbYRARuYpdE6BkVM8uJejZpYTT/xERWeDKGj4REVnHhE9EVCDyOuH/5wdfynYIREQ5I68TPhERtcnrhB9QXtQlIgoxnfBFxCsiS0XkP3Feu1REGkRkmfHzbXvDTI+fk5oTEYVZ6ZZ5DYDVAMoTvP6oqn6/4yHZh/meiKiNqRq+iFQDmAHgXmfDsRebdIiI2pht0vkjgJ8ACCQpc46IrBCRx0VkQMdD6zg26RARtUmZ8EVkJoAdqro4SbFnAdSo6tEAXgHwQIJtzRaROhGpa2hoSCvgSKkq8EOqOgMA7jg/Zg52IqKCY6aGPxnAWSKyEcA/AZwiIg9FFlDVXap62Hj6VwDj421IVeeraq2q1lZVVXUgbHN6de2EjbfOwNePrXZ8X0REuS5lwlfVG1S1WlVrAMwC8JqqXhRZRkT6Rjw9C8GLu0RElEPSHjxNRG4GUKeqzwC4WkTOAtAKYDeAS+0Jj4iI7GIp4avq6wBeNx7PjVh+A4Ab7AyMiIjsldd32hIRURsmfCKiAsGET0RUIJjwiYgKREEl/GJfQb1dIqJ2XDmnbYiVgRP+/d1J6Nut1LFYiIhynasTvhXjB3XPdghERFnFNg4iogLBhE9EVCBcnfAl2wEQEbmIqxM+R7snIjLP1QmfiIjMY8InIioQTPhERAWCCZ+IqEAw4RMRFQgmfCKiAmE64YuIV0SWish/4rxWIiKPisg6EVkkIjV2BklERB1npYZ/DRJPTn4FgC9UdRiAPwC4raOBERGRvUwlfBGpBjADwL0JipwN4AHj8eMAThUR3ghLRJRDzNbw/wjgJwACCV7vD2ATAKhqK4C9AHpEFxKR2SJSJyJ1DQ0NaYTbnirvtSUiMitlwheRmQB2qOriZMXiLIvJxqo6X1VrVbW2qqrKQphERNRRZmr4kwGcJSIbAfwTwCki8lBUmXoAAwBARHwAugHYbWOclv3q7DHZ3D0RUc5JmfBV9QZVrVbVGgCzALymqhdFFXsGwCXG43ONMllrb7lo4kB8a1JNtnZPRJST0p7xSkRuBlCnqs8AuA/A30VkHYI1+1k2xZdebBw4mYgohqWEr6qvA3jdeDw3YvkhAOfZGVhHsH8QEVEsV99pe8kJNXGXM98TEcVydcKfO3M01v16erbDICJyhbTb8HOBiMDnja3P854vIqJYrq7hExGReXmR8M8bX43+FaX40dQR2Q6FiChnubpJJ+T288YCAO57+1MA7KVDRBRPXtTwQzi2DhFRYnmV8EN44xURUay8SvihCj6bdIiIYuVXwjcG6GS+JyKKlV8JnzV8IqKE8irhF3mDb6fYl1dvi4jIFnnRLTPkguMHYnvjIXzv5GHZDoWIKOfkVcLvVOTFDWceke0wiIhyEts+iIgKBBM+EVGBMDOJeScReV9ElovIhyLyyzhlLhWRBhFZZvx825lwiYgoXWba8A8DOEVV94tIEYC3ReR5VV0YVe5RVf2+/SESEZEdUiZ8YzLy/cbTIuOHg9YQEbmMqTZ8EfGKyDIAOwC8rKqL4hQ7R0RWiMjjIjLA1iiJiKjDTCV8VfWr6jEAqgFMEJEjo4o8C6BGVY8G8AqAB+JtR0Rmi0idiNQ1NDR0JG4iIrLIUi8dVd0D4HUA06KW71LVw8bTvwIYn2D9+apaq6q1VVVVaYRLRETpStmGLyJVAFpUdY+IlAI4DcBtUWX6qupW4+lZAFan2u7ixYt3ishnacQMAD0B7Exz3UzI5fhyOTYgt+PL5diA3I4vl2MDcju+6NgGpbshM710+gJ4QES8CH4j+Jeq/kdEbgZQp6rPALhaRM4C0ApgN4BLU21UVdOu4otInarWpru+03I5vlyODcjt+HI5NiC348vl2IDcjs/O2Mz00lkBYFyc5XMjHt8A4AY7AiIiImfwTlsiogLh1oQ/P9sBpJDL8eVybEBux5fLsQG5HV8uxwbkdny2xSac+JuIqDC4tYZPREQWuS7hi8g0EVkrIutEZE4W9j9ARP4rIquNweSuMZbfJCKbIwaQOzNinRuMeNeKyBkZiHGjiKw04qgzlnUXkZdF5BPjd6WxXETkTiO+FSJyrINxjYw4PstEpFFErs3msRORv4nIDhFZFbHM8rESkUuM8p+IyCUOxna7iKwx9v+kiFQYy2tE5GDEMZwXsc544/OwzojflklAE8Rn+W/pxP90gtgejYhrowRHD8j4sUuSQ5z/3Kmqa34AeAGsBzAEQDGA5QBGZziGvgCONR53BfAxgNEAbgLwozjlRxtxlgAYbMTvdTjGjQB6Ri37HYA5xuM5AG4zHp8J4HkE536fCGBRBv+W2xDsU5y1YwfgRADHAliV7rEC0B3ABuN3pfG40qHYpgLwGY9vi4itJrJc1HbeBzDJiPt5ANMdPHaW/pZO/U/Hiy3q9d8DmJuNY5ckhzj+uXNbDX8CgHWqukFVmwH8E8DZmQxAVbeq6hLj8T4EbzLrn2SVswH8U1UPq+qnANYh+D4y7Wy0DXnxAICvRix/UIMWAqgQkb4ZiOdUAOtVNdnNd44fO1V9E8F7R6L3a+VYnYHgGFO7VfULAC8j6m50u2JT1ZdUtdV4uhDB4U4SMuIrV9X3NJglHox4P7bHl0Siv6Uj/9PJYjNq6ecD+EeybTh17JLkEMc/d25L+P0BbIp4Xo/kydZRIlKD4D0KocHkvm985fpb6OsYshOzAnhJRBaLyGxjWW817oY2fvfKYnwAMAvt/+Fy5dgB1o9VtuK8HMGaX8hgEVkqIm+IyBRjWX8jnkzGZuVvmY1jNwXAdlX9JGJZVo5dVA5x/HPntoQfr/0sK92MRKQLgH8DuFZVGwHcA2AogGMAbEXwKyOQnZgnq+qxAKYDuEpETkxSNuPxiUgxgkNwPGYsyqVjl0yieLJxDG9E8M72h41FWwEMVNVxAK4H8IiIlGchNqt/y2z8jb+J9pWNrBy7ODkkYdEEcViOz20Jvx5A5NDL1QC2ZDoICU4E828AD6vqEwCgqts1OKpoAMEB5EJNDxmPWVW3GL93AHjSiGV7qKnG+L0jW/EheCJaoqrbjThz5tgZrB6rjMZpXJybCeBCo6kBRlPJLuPxYgTbxUcYsUU2+zgaWxp/y0wfOx+ArwN4NCLmjB+7eDkEGfjcuS3hfwBguIgMNmqJswA8k8kAjPa/+wCsVtU7IpZHtnt/DUCod8AzAGaJSImIDAYwHMELQU7F11lEuoYeI3iRb5URR+gq/iUAno6I72KjJ8BEAHu1bSA8p7SrYeXKsYtg9Vi9CGCqiFQaTRhTjWW2E5FpAH4K4CxVbYpYXiXB8a4gIkMQPFYbjPj2ichE47N7ccT7cSI+q3/LTP9PnwZgjaqGm2oyfewS5RBk4nPX0SvOmf5B8Ir1xwiehW/Mwv6/hODXphUAlhk/ZwL4O4CVxvJnAPSNWOdGI961sKmHRJL4hiDY02E5gA9DxwhADwCvAvjE+N3dWC4A/mzEtxJArcPxlQHYBaBbxLKsHTsETzxbAbQgWGO6Ip1jhWB7+jrj5zIHY1uHYLtt6LM3zyh7jvH3Xg5gCYCvRGynFsHEux7A3TBuuHQoPst/Syf+p+PFZiy/H8CVUWUzeuyQOIc4/rnjnbZERAXCbU06RESUJiZ8IqICwYRPRFQgmPCJiAoEEz4RUYFgwiciKhBM+EREBYIJn4ioQPx/08TIDPK4DMkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(plt.plot([l.double() for l in losses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_dict = {}\n",
    "with open('../data/data_train_words.txt') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line[:-1] for line in lines]\n",
    "validate_words = sorted(list(set(lines)))\n",
    "for word in validate_words:\n",
    "    if word in glove_dict:\n",
    "        validate_dict[word] = glove_dict[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuloucn/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'somehow', 'nowhere', 'mistake', 'extent']\n",
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'nowhere', 'mistake', 'defect', 'somehow']\n",
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'somehow', 'nowhere', 'extent', 'defect']\n",
      "fault ['inevitably', 'arise', 'chaos', 'disconnect', 'uncertainty', 'turbulence', 'commotion', 'tension', 'constant', 'inevitable']\n",
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'nowhere', 'defect', 'mistake', 'somehow']\n",
      "fault ['satisfy', 'fail', 'intend', 'convince', 'agree', 'continue', 'threaten', 'seek', 'desire', 'inability']\n",
      "fault ['posture', 'shape', 'core', 'rigid', 'hierarchy', 'orientation', 'flexible', 'component', 'position', 'element']\n",
      "fault ['tip', 'mouth', 'fault', 'tiny', 'deep', 'edge', 'finger', 'narrow', 'rim', 'turn']\n",
      "fault ['tip', 'mouth', 'fault', 'tiny', 'edge', 'border', 'crossing', 'portion', 'lying', 'point']\n",
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'nowhere', 'mistake', 'somehow', 'defect']\n",
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'nowhere', 'defect', 'mistake', 'somehow']\n",
      "fault ['add', 'slice', 'fold', 'hold', 'arrange', 'give', 'remove', 'prepared', 'send', 'serve']\n",
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'defect', 'nowhere', 'mistake', 'extent']\n",
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'defect', 'nowhere', 'mistake', 'somehow']\n",
      "fault ['tip', 'crossing', 'portion', 'fault', 'mouth', 'border', 'rim', 'narrow', 'tiny', 'stream']\n",
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'mistake', 'somehow', 'nowhere', 'extent']\n",
      "fault ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'nowhere', 'somehow', 'mistake', 'defect']\n",
      "stringer ['freeman', 'cooper', 'fisher', 'griffin', 'wheeler', 'peck', 'mason', 'porter', 'barker', 'smith']\n",
      "stringer ['shrinkage', 'contraction', 'accumulation', 'evaporation', 'discernible', 'deformation', 'dislocation', 'atrophy', 'cortical', 'rupture']\n",
      "stringer ['glib', 'polite', 'dismissive', 'bristle', 'kindly', 'whisper', 'sarcastic', 'cheerfully', 'chuckle', 'disdain']\n",
      "stringer ['sparkling', 'crisp', 'taste', 'creamy', 'blend', 'tasting', 'flavor', 'refreshing', 'glaze', 'earthy']\n",
      "stringer ['griffin', 'peck', 'freeman', 'wheeler', 'cooper', 'fisher', 'bender', 'barker', 'pollack', 'sawyer']\n",
      "stringer ['bender', 'stringer', 'griffin', 'dickey', 'freedman', 'fisher', 'rouse', 'bowman', 'mason', 'dexter']\n",
      "gendarmerie ['gendarmerie', 'unit', 'auxiliary', 'unitary', 'cadre', 'grenadier', 'brigade', 'directorate', 'division', 'battalion']\n",
      "gendarmerie ['gendarmerie', 'sable', 'hydra', 'helmeted', 'grenadier', 'tracer', 'armored', 'detachment', 'garibaldi', 'brigade']\n",
      "gendarmerie ['gendarmerie', 'unit', 'auxiliary', 'unitary', 'cadre', 'grenadier', 'brigade', 'directorate', 'division', 'battalion']\n",
      "gendarmerie ['gendarmerie', 'sable', 'hydra', 'helmeted', 'grenadier', 'tracer', 'armored', 'garibaldi', 'detachment', 'brigade']\n",
      "meddling ['accountable', 'adequately', 'ignore', 'assure', 'legitimate', 'empower', 'deprive', 'punish', 'interfere', 'inform']\n",
      "meddling ['fervent', 'ardent', 'passionate', 'believer', 'fervor', 'zealous', 'admiration', 'disdain', 'devotion', 'embrace']\n",
      "meddling ['betray', 'inquiring', 'sympathize', 'ignore', 'plainly', 'dramatize', 'frankly', 'honestly', 'perceive', 'hurtful']\n",
      "recombination ['inverse', 'differentiation', 'exponential', 'recombination', 'generalized', 'discrete', 'inhibition', 'probability', 'computation', 'differential']\n",
      "recombination ['inverse', 'differentiation', 'exponential', 'discrete', 'computation', 'recombination', 'inhibition', 'probability', 'generalized', 'differential']\n",
      "recombination ['inverse', 'discrete', 'differentiation', 'exponential', 'spatial', 'computation', 'binary', 'generalized', 'probability', 'differential']\n",
      "recombination ['hierarchy', 'posture', 'orientation', 'core', 'paradigm', 'rigid', 'function', 'define', 'component', 'position']\n",
      "bristle ['surge', 'decline', 'decrease', 'offset', 'growth', 'drop', 'contraction', 'increase', 'shrinkage', 'slump']\n",
      "bristle ['bristle', 'glib', 'tongued', 'frown', 'kindly', 'pompous', 'faintly', 'characteristically', 'grin', 'mischievous']\n",
      "bristle ['kindly', 'ignore', 'dislike', 'shrug', 'frown', 'betray', 'embrace', 'suggestion', 'hint', 'countenance']\n",
      "bristle ['bristle', 'glib', 'tongued', 'characteristically', 'kindly', 'grin', 'chuckle', 'whisper', 'sarcastic', 'mischievous']\n",
      "bristle ['ethylene', 'urea', 'oxide', 'nitrogen', 'fertilizer', 'catalytic', 'lithium', 'manganese', 'benzene', 'chloride']\n",
      "bristle ['bristle', 'glib', 'tongued', 'characteristically', 'kindly', 'grin', 'chuckle', 'sarcastic', 'pompous', 'mischievous']\n",
      "bristle ['bristle', 'glib', 'tongued', 'characteristically', 'grin', 'kindly', 'sarcastic', 'chuckle', 'mischievous', 'whisper']\n",
      "bristle ['bristle', 'glib', 'dismissive', 'characteristically', 'polite', 'pompous', 'articulate', 'retort', 'sarcastic', 'mannered']\n",
      "bristle ['glib', 'bristle', 'tongued', 'characteristically', 'pompous', 'sarcastic', 'mischievous', 'kindly', 'grin', 'polite']\n",
      "bristle ['bristle', 'glib', 'tongued', 'characteristically', 'pompous', 'kindly', 'sarcastic', 'mischievous', 'polite', 'grin']\n",
      "bristle ['bristle', 'glib', 'tongued', 'characteristically', 'sarcastic', 'whisper', 'grin', 'mischievous', 'chuckle', 'pompous']\n",
      "bristle ['bristle', 'glib', 'tongued', 'characteristically', 'kindly', 'pompous', 'mischievous', 'grin', 'sarcastic', 'whisper']\n",
      "bristle ['bristle', 'glib', 'tongued', 'characteristically', 'pompous', 'sarcastic', 'mischievous', 'kindly', 'grin', 'whisper']\n",
      "bristle ['bristle', 'glib', 'characteristically', 'tongued', 'grin', 'whisper', 'kindly', 'mischievous', 'gentle', 'chuckle']\n",
      "bounty ['bounty', 'merit', 'reward', 'award', 'recipient', 'pedigree', 'bravery', 'ultimate', 'exceptional', 'prize']\n",
      "bounty ['calling', 'inviting', 'welcome', 'ordinary', 'faithful', 'merely', 'enthusiastic', 'asking', 'consider', 'giving']\n",
      "bounty ['incursion', 'shelling', 'retaliation', 'raid', 'onslaught', 'blockade', 'ambush', 'strip', 'attack', 'retaliatory']\n",
      "bounty ['bounty', 'crocodile', 'lion', 'shaggy', 'rapper', 'honey', 'thief', 'golden', 'pearl', 'witch']\n",
      "bounty ['wisdom', 'sense', 'essence', 'genuine', 'true', 'mind', 'belief', 'moral', 'sort', 'kind']\n",
      "bounty ['inviting', 'welcome', 'calling', 'enthusiastic', 'seize', 'independence', 'oppose', 'accept', 'favor', 'asking']\n",
      "bounty ['bomb', 'terrorist', 'attack', 'responsible', 'destroy', 'suspected', 'killing', 'suicide', 'fire', 'security']\n",
      "bounty ['bounty', 'shaggy', 'crocodile', 'rapper', 'vampire', 'witch', 'thief', 'hound', 'pimp', 'honey']\n",
      "bounty ['bounty', 'crocodile', 'jolly', 'hunter', 'lion', 'hunt', 'hound', 'dove', 'thief', 'ransom']\n",
      "bounty ['feeding', 'feed', 'spread', 'prevent', 'blood', 'sick', 'animal', 'eating', 'dying', 'normally']\n",
      "arthritis ['degenerative', 'arthritis', 'heal', 'spinal', 'chronic', 'paralysis', 'tendon', 'incurable', 'traumatic', 'bleeding']\n",
      "arthritis ['arthritis', 'degenerative', 'heal', 'chronic', 'cure', 'suffering', 'traumatic', 'spinal', 'heart', 'stomach']\n",
      "trinity ['council', 'committee', 'appointment', 'decision', 'secretary', 'representative', 'member', 'commission', 'authority', 'board']\n",
      "trinity ['people', 'least', 'ordinary', 'speak', 'alone', 'living', 'person', 'mostly', 'have', 'here']\n",
      "trinity ['contemporary', 'famous', 'inspiration', 'inspired', 'art', 'music', 'audience', 'folk', 'notable', 'passion']\n",
      "trinity ['peck', 'freeman', 'griffin', 'fisher', 'mason', 'cooper', 'porter', 'wheeler', 'baker', 'walker']\n",
      "trinity ['conservative', 'liberal', 'political', 'party', 'leading', 'influential', 'prominent', 'majority', 'politics', 'favor']\n",
      "ravine ['tip', 'mouth', 'tiny', 'crossing', 'rim', 'slope', 'lying', 'border', 'edge', 'portion']\n",
      "ravine ['tip', 'fault', 'slope', 'ridge', 'deep', 'edge', 'mouth', 'southern', 'area', 'rough']\n",
      "ravine ['jutting', 'porous', 'rim', 'slope', 'sloping', 'thickly', 'bristle', 'embankment', 'skirting', 'ravine']\n",
      "ravine ['tip', 'rim', 'tiny', 'crossing', 'mouth', 'border', 'slope', 'northwest', 'southwest', 'northernmost']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchy ['belief', 'attitude', 'stance', 'sense', 'expression', 'ideology', 'embrace', 'hierarchy', 'moral', 'argument']\n",
      "hierarchy ['concurrent', 'transmission', 'parallel', 'alignment', 'configuration', 'loop', 'system', 'multiple', 'continuous', 'computation']\n",
      "hierarchy ['conservative', 'liberal', 'party', 'political', 'politics', 'opinion', 'leaning', 'majority', 'debate', 'support']\n",
      "hierarchy ['rigid', 'posture', 'hierarchy', 'core', 'orientation', 'functional', 'component', 'integral', 'function', 'effective']\n",
      "map ['episode', 'single', 'series', 'sequence', 'appear', 'show', 'same', 'list', 'character', 'appearance']\n",
      "map ['sequence', 'single', 'same', 'episode', 'actual', 'different', 'instance', 'complete', 'feature', 'form']\n",
      "map ['same', 'different', 'instance', 'example', 'people', 'number', 'least', 'present', 'person', 'exactly']\n",
      "map ['instead', 'add', 'serve', 'regular', 'hold', 'full', 'separate', 'same', 'giving', 'rather']\n",
      "map ['function', 'different', 'discrete', 'component', 'specific', 'corresponding', 'normal', 'example', 'functional', 'definition']\n",
      "map ['sequence', 'corresponding', 'singular', 'variation', 'iteration', 'actual', 'element', 'random', 'discrete', 'definition']\n",
      "map ['episode', 'reality', 'show', 'appearance', 'series', 'moment', 'titled', 'story', 'ever', 'memorable']\n",
      "map ['affirm', 'declare', 'uphold', 'proclaim', 'reiterate', 'recognize', 'reconsider', 'accept', 'intend', 'renounce']\n",
      "harrier ['harrier', 'falcon', 'phantom', 'cougar', 'hawk', 'hawker', 'jaguar', 'leopard', 'sparrow', 'wasp']\n",
      "harrier ['harrier', 'falcon', 'hawker', 'peregrine', 'wasp', 'hawk', 'bane', 'cougar', 'offshoot', 'sis']\n",
      "harrier ['harrier', 'falcon', 'phantom', 'hawk', 'conqueror', 'hawker', 'tiger', 'gunner', 'wasp', 'fighter']\n",
      "harrier ['savagery', 'imperil', 'medusa', 'yoke', 'precipice', 'encroachment', 'infidel', 'devastate', 'abominable', 'deplore']\n",
      "harrier ['harrier', 'falcon', 'sparrow', 'wasp', 'thunderbolt', 'phantom', 'discoverer', 'conqueror', 'cougar', 'slayer']\n",
      "manage ['heal', 'bind', 'regenerate', 'differentiate', 'confront', 'rid', 'reconcile', 'mend', 'remove', 'isolate']\n",
      "manage ['bowling', 'fitness', 'bowler', 'serial', 'instructional', 'slater', 'career', 'featured', 'series', 'columbine']\n",
      "manage ['people', 'alone', 'least', 'forced', 'rest', 'still', 'leave', 'already', 'have', 'coming']\n",
      "manage ['posture', 'shape', 'core', 'rigid', 'hierarchy', 'orientation', 'position', 'component', 'flexible', 'element']\n",
      "manage ['pace', 'slow', 'speed', 'fast', 'steady', 'acceleration', 'rapid', 'momentum', 'dynamic', 'continuous']\n",
      "manage ['ignore', 'honestly', 'understand', 'frankly', 'perceive', 'explain', 'understandable', 'plainly', 'answer', 'relate']\n",
      "manage ['wisdom', 'sense', 'belief', 'genuine', 'moral', 'mind', 'essence', 'true', 'humility', 'understand']\n",
      "manage ['satisfy', 'fail', 'intend', 'agree', 'convince', 'seek', 'continue', 'threaten', 'assure', 'desire']\n",
      "manage ['satisfy', 'fail', 'intend', 'convince', 'agree', 'seek', 'continue', 'threaten', 'assure', 'desire']\n",
      "manage ['fault', 'problem', 'lie', 'prone', 'error', 'difficult', 'nowhere', 'mistake', 'defect', 'somehow']\n",
      "manage ['desire', 'understand', 'realize', 'satisfy', 'sense', 'need', 'opportunity', 'inability', 'necessarily', 'willingness']\n",
      "manage ['satisfy', 'retain', 'fail', 'need', 'bring', 'necessary', 'seek', 'manage', 'able', 'opportunity']\n",
      "manage ['need', 'help', 'needs', 'keep', 'bring', 'manage', 'rest', 'remain', 'survive', 'continue']\n",
      "manage ['convince', 'able', 'intend', 'manage', 'satisfy', 'help', 'continue', 'agree', 'want', 'need']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(0, 250): #len(definition_indices)\n",
    "    if count >= 100:\n",
    "        break\n",
    "    x = torch.tensor(definition_indices[i])\n",
    "    #print(x.shape)\n",
    "    init_hidden = model.initHidden()\n",
    "    tag_scores = model.forward(x.view(x.shape[0], 1), init_hidden)\n",
    "    #print(tag_scores[0].shape, y.shape)\n",
    "    if words[i] in validate_dict: \n",
    "        count += 1\n",
    "        #print(words[i])\n",
    "        y_array = np.array(glove_dict[words[i]]) if words[i] in glove_dict else np.random.normal(scale=0.6, size=(50,))\n",
    "        y = torch.tensor(y).double()\n",
    "        y_pred = tag_scores[0].view((tag_scores[0].shape[2])).double()\n",
    "        eval.top_ten_hundred(validate_dict, words[i], y_pred.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print(eval.compute_th_accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 56, 100)\n"
     ]
    }
   ],
   "source": [
    "print(eval.compute_th_accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
