{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yuloucn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils\n",
    "import torch.nn.functional as F\n",
    "from torchnlp.nn import Attention\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "from model_embeddings import ModelEmbeddings\n",
    "from evaluator import Evaluator\n",
    "from vocab import Vocab, VocabEntry\n",
    "from utils import read_corpus, pad_sents, batch_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "ft = fasttext.load_model('../data/cc.en.300.bin')\n",
    "print(ft.get_dimension())\n",
    "fasttext.util.reduce_model(ft, 100)\n",
    "print(ft.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11151148 -0.04900418  0.0288552   0.04092126  0.19804892  0.00216246\n",
      "  0.03674458  0.09451544 -0.12428932  0.0465628  -0.1439622   0.17689864\n",
      "  0.05874445 -0.07696565  0.03921199 -0.03626664  0.02874357  0.07096066\n",
      "  0.05633339  0.17098126  0.01038988  0.14626968 -0.1002604   0.07075594\n",
      "  0.03674031  0.03039704 -0.0011446   0.00437543 -0.07224936 -0.04147346\n",
      "  0.04753026  0.01315587 -0.0048466  -0.00099305 -0.08950087 -0.06880744\n",
      " -0.03843674 -0.04456125 -0.02063351  0.05325395 -0.07706098 -0.04812273\n",
      " -0.03669549 -0.0366352  -0.02296097 -0.02639301 -0.0252313   0.04095381\n",
      " -0.0153988  -0.06415159  0.00408742  0.05854311 -0.03529252  0.01532949\n",
      " -0.02925256 -0.09079327  0.02499075  0.0022867  -0.06236723 -0.06313032\n",
      "  0.02734467 -0.08804032 -0.01031698 -0.02277267 -0.06588884  0.0024988\n",
      "  0.0450968   0.03720963 -0.01330832 -0.03214228 -0.03183099 -0.01358417\n",
      "  0.04029506  0.06616739  0.00523137 -0.01328973  0.01361618  0.03699441\n",
      "  0.02201992 -0.03893679 -0.04548992  0.02037135  0.05007319 -0.05254434\n",
      "  0.01804875 -0.03365846 -0.0061455   0.03813035 -0.015855    0.02492434\n",
      " -0.06998907 -0.00840895  0.06436936 -0.00116885  0.00881286 -0.07675131\n",
      "  0.07003712 -0.09161227 -0.07241979 -0.02636037]\n",
      "[(0.8396024107933044, 'zhongshan'), (0.8325980305671692, 'jiangsu'), (0.8275330662727356, 'fujian'), (0.8180376291275024, 'shenyang'), (0.812710165977478, 'taichung'), (0.8106772899627686, 'chengdu'), (0.8105600476264954, 'wenzhou'), (0.8058239817619324, 'guangdong'), (0.8030492663383484, 'zhuhai'), (0.800834596157074, 'chongqing')]\n"
     ]
    }
   ],
   "source": [
    "print(ft.get_word_vector('nihao'))\n",
    "print(ft.get_nearest_neighbors('changsha'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = []\n",
    "unparsed_definition = []\n",
    "words = []\n",
    "src_sents = read_corpus('../data/data_train_definitions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data_train_words.txt') as f:\n",
    "    words += f.read().splitlines()\n",
    "    \n",
    "with open('../data/data_train_definitions.txt') as f:\n",
    "    unparsed_definition += f.read().splitlines()\n",
    "    definitions += [word_tokenize(a) for a in unparsed_definition]\n",
    "\n",
    "training_data = [(definitions[i], words[i]) for i in range(len(words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = pickle.load(open(\"../data/train_valid_test.data\", \"rb\"))\n",
    "\n",
    "unparsed_definition = [t[1] for t in train]\n",
    "definitions = [word_tokenize(a) for a in unparsed_definition]\n",
    "words = [t[0] for t in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word types: 34192, number of word types w/ frequency >= 0: 34192\n",
      "34196\n",
      "63294\n"
     ]
    }
   ],
   "source": [
    "eval = Evaluator()\n",
    "# fasttext_dict = eval.load_vectors(fname =\"../data/wiki-news-300d-1M-subword.vec\", max_line = 10000000)\n",
    "fasttext_dict = {}\n",
    "sub_fasttext_dict = {}\n",
    "#only train words in the dictionary\n",
    "for i in range(len(words)-1, -1, -1):\n",
    "    fasttext_dict[words[i]] = ft.get_word_vector(words[i])\n",
    "    sub_fasttext_dict[words[i]] = fasttext_dict[words[i]]\n",
    "        \n",
    "# high_freq_dict = eval.load_vectors(fname =\"../data/wiki-news-300d-1M-subword.vec\", max_line = 30000)\n",
    "# sub_fasttext_dict.update()\n",
    "\n",
    "src_sents = read_corpus('../data/data_train_definitions.txt')\n",
    "vocab = VocabEntry.from_corpus(definitions, 1000000, 0)\n",
    "    \n",
    "print(len(vocab))\n",
    "\n",
    "for w in words:\n",
    "    vocab.add(w)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/words_defs_dict.train\", \"wb\") as f:\n",
    "    pickle.dump((words, definitions, sub_fasttext_dict), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(words) == len(definitions))\n",
    "training_data = [(definitions[i], words[i]) for i in range(len(words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, src_pad_token_idx, device = \"cpu\", non_trainable=True):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim, src_pad_token_idx)\n",
    "    emb_layer.weight.data.copy_(torch.from_numpy(weights_matrix).float().to(device)) #figure out what is here\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "class ModelEmbeddings(nn.Module): \n",
    "    \"\"\"\n",
    "    Class that converts input words to their embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_size, vocab, fasttext_model):\n",
    "        \"\"\"\n",
    "        Init the Embedding layers.\n",
    "\n",
    "        @param embed_size (int): Embedding size (dimensionality)\n",
    "        @param vocab (VocabEntry)\n",
    "        \"\"\"\n",
    "        super(ModelEmbeddings, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        matrix_len = len(vocab)\n",
    "        weights_matrix = np.zeros((matrix_len, self.embed_size))\n",
    "        words_found = 0\n",
    "        #print(len(vocab), weights_matrix.shape)\n",
    "        for word, index in vocab.word2id.items():\n",
    "            weights_matrix[index] = np.array(fasttext_model.get_word_vector(word))\n",
    "        \n",
    "#         for word, index in vocab.word2id.items():\n",
    "#             try:\n",
    "#                 weights_matrix[index] = np.array(fasttext_dict[word])\n",
    "#                 words_found += 1\n",
    "#             except KeyError:\n",
    "#                 weights_matrix[index] = np.random.normal(scale=0.6, size=(self.embed_size,))\n",
    "\n",
    "        # default values\n",
    "        src_pad_token_idx = vocab['<pad>']\n",
    "        self.source = create_emb_layer(weights_matrix, src_pad_token_idx, device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GRUModel(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, vocab, fasttext_dict):\n",
    "#         super(GRUModel, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embedding = ModelEmbeddings(input_size, vocab, fasttext_dict)\n",
    "#         self.gru = nn.GRU(input_size, hidden_size)\n",
    "        \n",
    "#         self.linear = nn.Linear(self.hidden_size, self.hidden_size, bias = True)\n",
    "\n",
    "#     def forward(self, input_, hidden, lengths , dropout_rate = 0.3):\n",
    "#         embedded = self.embedding.source[0](input_)\n",
    "#         embedded = pack_padded_sequence(embedded, lengths)\n",
    "#         output, hidden = self.gru(embedded, hidden)\n",
    "#         dropout = nn.Dropout(dropout_rate)\n",
    "#         hidden_dropped = dropout(hidden.permute(1,0,2)) # you dont need dropout in validation\n",
    "#         projected = self.linear(hidden_dropped)\n",
    "#         return projected, hidden\n",
    "\n",
    "#     def initHidden(self, batch_size, device = None):\n",
    "#         return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, vocab, fasttext_model):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.vocab = vocab\n",
    "        self.embedding = ModelEmbeddings(input_size, vocab, fasttext_model)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional = True)\n",
    "        self.linear = nn.Linear(self.hidden_size * 2, self.hidden_size, bias = True)\n",
    "        self.linear2 = nn.Linear(self.hidden_size, self.hidden_size, bias = True)\n",
    "        self.attention = Attention(self.hidden_size)\n",
    "\n",
    "    def forward(self, input_, hidden, lengths, dropout_rate = 0.3):\n",
    "        embedded = self.embedding.source[0](input_)\n",
    "        embedded = pack_padded_sequence(embedded, lengths)\n",
    "        output, (h_n, c_n) = self.lstm(embedded)   \n",
    "        hidden_permuted = h_n.contiguous().view(1, -1, self.hidden_size * 2).permute(1,0,2)\n",
    "         \n",
    "        projected = self.linear(hidden_permuted)\n",
    "        dropout = nn.Dropout(dropout_rate)\n",
    "        projected_dropped = dropout(projected)\n",
    "        projected2 = self.linear2(projected_dropped)\n",
    "        return projected2, hidden\n",
    "\n",
    "    def initHidden(self, batch_size, device = None):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(100, 100, vocab, ft)\n",
    "loss_function = nn.CosineEmbeddingLoss(margin=0.0, reduction='sum')\n",
    "l1loss = nn.L1Loss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GRUModel(50, 50, vocab, fasttext_dict)\n",
    "# loss_function = nn.L1Loss(reduction = \"sum\")\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_dropped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-b1488fdaf718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_input_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0minit_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0my_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords2indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0my_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-39b993319c18>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, hidden, lengths, dropout_rate)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mprojected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dropped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mprojected_dropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprojected2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojected_dropped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hidden_dropped' is not defined"
     ]
    }
   ],
   "source": [
    "#check overfit\n",
    "\n",
    "definition_indices = vocab.words2indices(definitions)\n",
    "words_in = 0\n",
    "words_out = 0\n",
    "\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "losses = []\n",
    "\n",
    "batch_size = 2048\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "loss_function = nn.CosineEmbeddingLoss(margin=0.0, reduction='sum')\n",
    "#loss_function = nn.L1Loss(reduction='none')\n",
    "\n",
    "for src_sents, tgt_word in batch_iter(training_data, batch_size, False):\n",
    "    for i in range(1000):\n",
    "        model.zero_grad()\n",
    "        x_lengths = [len(sent) for sent in src_sents]\n",
    "        x = vocab.to_input_tensor(src_sents, \"cpu\")\n",
    "        init_hidden = model.initHidden(len(src_sents), \"cpu\")\n",
    "        tag_scores = model.forward(x, init_hidden, x_lengths)\n",
    "        y_indices = vocab.words2indices(tgt_word)\n",
    "        y_array = model.embedding.source[0](torch.tensor(y_indices, device = device)).double()\n",
    "        y_pred = tag_scores[0].squeeze(dim = 1).double()\n",
    "        y_match = torch.ones(1,)\n",
    "        loss = loss_function(y_pred, y_array, y_match)\n",
    "        #print(y_pred.shape, y_match.shape, loss.shape, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        losses.append(loss)\n",
    "        if i % 100 == 0:\n",
    "            print(i, loss)\n",
    "    break\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(plt.plot([l.double() for l in losses][:1200]))\n",
    "\n",
    "model.zero_grad()\n",
    "x_lengths = [len(sent) for sent in src_sents]\n",
    "x = vocab.to_input_tensor(src_sents, \"cpu\")\n",
    "init_hidden = model.initHidden(len(src_sents), \"cpu\")\n",
    "tag_scores = model.forward(x, init_hidden, x_lengths)\n",
    "y_pred = tag_scores[0].squeeze(dim = 1).double()\n",
    "\n",
    "validate_dict = dict([(w, model.embedding.source[0](torch.tensor(vocab[w])).numpy()) for w in set(words)])\n",
    "print(len(validate_dict))\n",
    "\n",
    "print(y_pred.shape)\n",
    "for i in range(len(y_pred)):\n",
    "    eval.top_ten_hundred(validate_dict, tgt_word[i], y_pred[i].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-04d9cb81fc15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(y_pred.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2, target)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_embedding_loss\u001b[0;34m(input1, input2, target, margin, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "definition_indices = vocab.words2indices(definitions)\n",
    "words_in = 0\n",
    "words_out = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "losses = []\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "for epoch in range(5000):\n",
    "    for src_sents, tgt_word in batch_iter(training_data, batch_size, False):\n",
    "        model.zero_grad()\n",
    "        x_lengths = [len(sent) for sent in src_sents]\n",
    "        x = vocab.to_input_tensor(src_sents, device)\n",
    "        init_hidden = model.initHidden(len(src_sents), device)\n",
    "        tag_scores = model.forward(x, init_hidden, x_lengths)\n",
    "        y_array = model.embedding.source[0](torch.tensor(vocab.words2indices(tgt_word))).double()\n",
    "        y_pred = tag_scores[0].squeeze(dim = 1).double()\n",
    "        y_match = torch.ones(1,)\n",
    "        #loss = loss_function(y_pred, y_array, y_match)\n",
    "        loss = l1loss(y_pred.transpose(0,1), y_array.transpose(0,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss)\n",
    "    print(epoch, loss, timeit.default_timer() - start)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(plt.plot([l.double() for l in losses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(plt.plot([l.double() for l in losses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "x_lengths = [len(sent) for sent in src_sents]\n",
    "x = vocab.to_input_tensor(src_sents, device)\n",
    "init_hidden = model.initHidden(len(src_sents), device)\n",
    "tag_scores = model.forward(x, init_hidden, x_lengths)\n",
    "y_pred = tag_scores[0].squeeze(dim = 1).double()\n",
    "\n",
    "validate_dict = dict([(w, model.embedding.source[0](torch.tensor(vocab[w])).detach().numpy()) for w in set(words)])\n",
    "print(len(validate_dict))\n",
    "\n",
    "print(y_pred.shape)\n",
    "for i in range(len(y_pred)):\n",
    "    eval.top_ten_hundred(validate_dict, tgt_word[i], y_pred[i].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
