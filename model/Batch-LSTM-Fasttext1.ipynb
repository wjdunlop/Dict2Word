{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yuloucn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils\n",
    "import torch.nn.functional as F\n",
    "from torchnlp.nn import Attention\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "from model_embeddings import ModelEmbeddings\n",
    "from evaluator import Evaluator\n",
    "from vocab import Vocab, VocabEntry\n",
    "from utils import read_corpus, pad_sents, batch_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "ft = fasttext.load_model('../data/cc.en.300.bin')\n",
    "print(ft.get_dimension())\n",
    "fasttext.util.reduce_model(ft, 100)\n",
    "print(ft.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11151148 -0.04900418  0.0288552   0.04092126  0.19804892  0.00216246\n",
      "  0.03674458  0.09451544 -0.12428932  0.0465628  -0.1439622   0.17689864\n",
      "  0.05874445 -0.07696565  0.03921199 -0.03626664  0.02874357  0.07096066\n",
      "  0.05633339  0.17098126  0.01038988  0.14626968 -0.1002604   0.07075594\n",
      "  0.03674031  0.03039704 -0.0011446   0.00437543 -0.07224936 -0.04147346\n",
      "  0.04753026  0.01315587 -0.0048466  -0.00099305 -0.08950087 -0.06880744\n",
      " -0.03843674 -0.04456125 -0.02063351  0.05325395 -0.07706098 -0.04812273\n",
      " -0.03669549 -0.0366352  -0.02296097 -0.02639301 -0.0252313   0.04095381\n",
      " -0.0153988  -0.06415159  0.00408742  0.05854311 -0.03529252  0.01532949\n",
      " -0.02925256 -0.09079327  0.02499075  0.0022867  -0.06236723 -0.06313032\n",
      "  0.02734467 -0.08804032 -0.01031698 -0.02277267 -0.06588884  0.0024988\n",
      "  0.0450968   0.03720963 -0.01330832 -0.03214228 -0.03183099 -0.01358417\n",
      "  0.04029506  0.06616739  0.00523137 -0.01328973  0.01361618  0.03699441\n",
      "  0.02201992 -0.03893679 -0.04548992  0.02037135  0.05007319 -0.05254434\n",
      "  0.01804875 -0.03365846 -0.0061455   0.03813035 -0.015855    0.02492434\n",
      " -0.06998907 -0.00840895  0.06436936 -0.00116885  0.00881286 -0.07675131\n",
      "  0.07003712 -0.09161227 -0.07241979 -0.02636037]\n",
      "[(0.8396024107933044, 'zhongshan'), (0.8325980305671692, 'jiangsu'), (0.8275330662727356, 'fujian'), (0.8180376291275024, 'shenyang'), (0.812710165977478, 'taichung'), (0.8106772899627686, 'chengdu'), (0.8105600476264954, 'wenzhou'), (0.8058239817619324, 'guangdong'), (0.8030492663383484, 'zhuhai'), (0.800834596157074, 'chongqing')]\n"
     ]
    }
   ],
   "source": [
    "print(ft.get_word_vector('nihao'))\n",
    "print(ft.get_nearest_neighbors('changsha'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = []\n",
    "unparsed_definition = []\n",
    "words = []\n",
    "src_sents = read_corpus('../data/data_train_definitions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data_train_words.txt') as f:\n",
    "    words += f.read().splitlines()\n",
    "    \n",
    "with open('../data/data_train_definitions.txt') as f:\n",
    "    unparsed_definition += f.read().splitlines()\n",
    "    definitions += [word_tokenize(a) for a in unparsed_definition]\n",
    "\n",
    "training_data = [(definitions[i], words[i]) for i in range(len(words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = pickle.load(open(\"../data/train_valid_test.data\", \"rb\"))\n",
    "\n",
    "unparsed_definition = [t[1] for t in train]\n",
    "definitions = [word_tokenize(a) for a in unparsed_definition]\n",
    "words = [t[0] for t in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word types: 34192, number of word types w/ frequency >= 0: 34192\n",
      "34196\n",
      "63294\n"
     ]
    }
   ],
   "source": [
    "eval = Evaluator()\n",
    "# fasttext_dict = eval.load_vectors(fname =\"../data/wiki-news-300d-1M-subword.vec\", max_line = 10000000)\n",
    "fasttext_dict = {}\n",
    "sub_fasttext_dict = {}\n",
    "#only train words in the dictionary\n",
    "for i in range(len(words)-1, -1, -1):\n",
    "    fasttext_dict[words[i]] = ft.get_word_vector(words[i])\n",
    "    sub_fasttext_dict[words[i]] = fasttext_dict[words[i]]\n",
    "        \n",
    "# high_freq_dict = eval.load_vectors(fname =\"../data/wiki-news-300d-1M-subword.vec\", max_line = 30000)\n",
    "# sub_fasttext_dict.update()\n",
    "\n",
    "src_sents = read_corpus('../data/data_train_definitions.txt')\n",
    "vocab = VocabEntry.from_corpus(definitions, 1000000, 0)\n",
    "    \n",
    "print(len(vocab))\n",
    "\n",
    "for w in words:\n",
    "    vocab.add(w)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/words_defs_dict.train\", \"wb\") as f:\n",
    "    pickle.dump((words, definitions, sub_fasttext_dict), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(words) == len(definitions))\n",
    "training_data = [(definitions[i], words[i]) for i in range(len(words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, src_pad_token_idx, device = \"cpu\", non_trainable=True):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim, src_pad_token_idx)\n",
    "    emb_layer.weight.data.copy_(torch.from_numpy(weights_matrix).float().to(device)) #figure out what is here\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "class ModelEmbeddings(nn.Module): \n",
    "    \"\"\"\n",
    "    Class that converts input words to their embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_size, vocab, fasttext_model):\n",
    "        \"\"\"\n",
    "        Init the Embedding layers.\n",
    "\n",
    "        @param embed_size (int): Embedding size (dimensionality)\n",
    "        @param vocab (VocabEntry)\n",
    "        \"\"\"\n",
    "        super(ModelEmbeddings, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        matrix_len = len(vocab)\n",
    "        weights_matrix = np.zeros((matrix_len, self.embed_size))\n",
    "        words_found = 0\n",
    "        #print(len(vocab), weights_matrix.shape)\n",
    "        for word, index in vocab.word2id.items():\n",
    "            weights_matrix[index] = np.array(fasttext_model.get_word_vector(word))\n",
    "        \n",
    "#         for word, index in vocab.word2id.items():\n",
    "#             try:\n",
    "#                 weights_matrix[index] = np.array(fasttext_dict[word])\n",
    "#                 words_found += 1\n",
    "#             except KeyError:\n",
    "#                 weights_matrix[index] = np.random.normal(scale=0.6, size=(self.embed_size,))\n",
    "\n",
    "        # default values\n",
    "        src_pad_token_idx = vocab['<pad>']\n",
    "        self.source = create_emb_layer(weights_matrix, src_pad_token_idx, device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GRUModel(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, vocab, fasttext_dict):\n",
    "#         super(GRUModel, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embedding = ModelEmbeddings(input_size, vocab, fasttext_dict)\n",
    "#         self.gru = nn.GRU(input_size, hidden_size)\n",
    "        \n",
    "#         self.linear = nn.Linear(self.hidden_size, self.hidden_size, bias = True)\n",
    "\n",
    "#     def forward(self, input_, hidden, lengths , dropout_rate = 0.3):\n",
    "#         embedded = self.embedding.source[0](input_)\n",
    "#         embedded = pack_padded_sequence(embedded, lengths)\n",
    "#         output, hidden = self.gru(embedded, hidden)\n",
    "#         dropout = nn.Dropout(dropout_rate)\n",
    "#         hidden_dropped = dropout(hidden.permute(1,0,2)) # you dont need dropout in validation\n",
    "#         projected = self.linear(hidden_dropped)\n",
    "#         return projected, hidden\n",
    "\n",
    "#     def initHidden(self, batch_size, device = None):\n",
    "#         return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, vocab, fasttext_model):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.vocab = vocab\n",
    "        self.embedding = ModelEmbeddings(input_size, vocab, fasttext_model)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional = True)\n",
    "        self.linear = nn.Linear(self.hidden_size * 2, self.hidden_size, bias = True)\n",
    "        self.linear2 = nn.Linear(self.hidden_size, self.hidden_size, bias = True)\n",
    "        self.attention = Attention(self.hidden_size)\n",
    "\n",
    "    def forward(self, input_, hidden, lengths, dropout_rate = 0.3):\n",
    "        embedded = self.embedding.source[0](input_)\n",
    "        embedded = pack_padded_sequence(embedded, lengths)\n",
    "        output, (h_n, c_n) = self.lstm(embedded)   \n",
    "        hidden_permuted = h_n.contiguous().view(1, -1, self.hidden_size * 2).permute(1,0,2)\n",
    "         \n",
    "        projected = self.linear(hidden_permuted)\n",
    "        dropout = nn.Dropout(dropout_rate)\n",
    "        projected_dropped = dropout(projected)\n",
    "        projected2 = self.linear2(projected_dropped)\n",
    "        return projected2, hidden\n",
    "\n",
    "    def initHidden(self, batch_size, device = None):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(100, 100, vocab, ft)\n",
    "loss_function = nn.CosineEmbeddingLoss(margin=0.0, reduction='mean')\n",
    "l1loss = nn.L1Loss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GRUModel(50, 50, vocab, fasttext_dict)\n",
    "# loss_function = nn.L1Loss(reduction = \"sum\")\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.0026, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "100 tensor(0.0013, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "200 tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "300 tensor(0.0030, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "400 tensor(0.0009, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "500 tensor(0.0002, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "600 tensor(0.0004, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "700 tensor(0.0008, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "800 tensor(0.0027, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "900 tensor(0.0015, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Time:  10.614251816063188\n",
      "[<matplotlib.lines.Line2D object at 0x1a5e4030f0>]\n",
      "53079\n",
      "torch.Size([8, 100])\n",
      "['batting', 'bowler', 'bowlers', 'batsmen', 'innings', 'outfield', 'batted', 'batsman', 'bat', 'bowling']\n",
      "batting ['batting', 'bowler', 'bowlers', 'batsmen', 'innings', 'outfield', 'batted', 'batsman', 'bat', 'bowling']\n",
      "['drifted', 'crept', 'slipped', 'drifting', 'veered', 'clung', 'retreated', 'meandered', 'shifted', 'vanished']\n",
      "drifted ['drifted', 'crept', 'slipped', 'drifting', 'veered', 'clung', 'retreated', 'meandered', 'shifted', 'vanished']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-c3339e9b6be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_ten_hundred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Development/Dict2Word/model/evaluator.py\u001b[0m in \u001b[0;36mtop_ten_hundred\u001b[0;34m(self, embeddings_dict, answer, guess)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mth_tracker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mtop_hundred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_closest_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mtop_ten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_hundred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_ten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/Dict2Word/model/evaluator.py\u001b[0m in \u001b[0;36mfind_closest_embeddings\u001b[0;34m(self, embeddings_dict, embedding, k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[1;32m     53\u001b[0m         ans = sorted(embeddings_dict.keys(),\n\u001b[0;32m---> 54\u001b[0;31m                       key=lambda word: spatial.distance.cosine(embeddings_dict[word], embedding))\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/Dict2Word/model/evaluator.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[1;32m     53\u001b[0m         ans = sorted(embeddings_dict.keys(),\n\u001b[0;32m---> 54\u001b[0;31m                       key=lambda word: spatial.distance.cosine(embeddings_dict[word], embedding))\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;31m# cosine distance is also referred to as 'uncentered correlation',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;31m#   or 'reflective correlation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \"\"\"\n\u001b[1;32m    686\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m_validate_vector\u001b[0;34m(u, dtype)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m# XXX Is order='c' really necessary?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;31m# Ensure values such as u=1 and u=[1] still return 1-D arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m     \"\"\"Convert the input to an array.\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check overfit\n",
    "\n",
    "definition_indices = vocab.words2indices(definitions)\n",
    "words_in = 0\n",
    "words_out = 0\n",
    "\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "losses = []\n",
    "\n",
    "batch_size = 8\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "loss_function = nn.CosineEmbeddingLoss(margin=0.0, reduction='mean')\n",
    "#loss_function = nn.L1Loss(reduction='none')\n",
    "\n",
    "for src_sents, tgt_word in batch_iter(training_data, batch_size, False):\n",
    "    for i in range(1000):\n",
    "        model.zero_grad()\n",
    "        x_lengths = [len(sent) for sent in src_sents]\n",
    "        x = vocab.to_input_tensor(src_sents, \"cpu\")\n",
    "        init_hidden = model.initHidden(len(src_sents), \"cpu\")\n",
    "        tag_scores = model.forward(x, init_hidden, x_lengths)\n",
    "        y_indices = vocab.words2indices(tgt_word)\n",
    "        y_array = model.embedding.source[0](torch.tensor(y_indices, device = device)).double()\n",
    "        y_pred = tag_scores[0].squeeze(dim = 1).double()\n",
    "        y_match = torch.ones(y_pred.shape[0])\n",
    "        loss = loss_function(y_pred, y_array, y_match)\n",
    "        #print(y_pred.shape, y_match.shape, loss.shape, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        losses.append(loss)\n",
    "        if i % 100 == 0:\n",
    "            print(i, loss)\n",
    "    break\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(plt.plot([l.double() for l in losses][:1200]))\n",
    "\n",
    "model.zero_grad()\n",
    "x_lengths = [len(sent) for sent in src_sents]\n",
    "x = vocab.to_input_tensor(src_sents, \"cpu\")\n",
    "init_hidden = model.initHidden(len(src_sents), \"cpu\")\n",
    "tag_scores = model.forward(x, init_hidden, x_lengths)\n",
    "y_pred = tag_scores[0].squeeze(dim = 1).double()\n",
    "\n",
    "validate_dict = dict([(w, model.embedding.source[0](torch.tensor(vocab[w])).numpy()) for w in set(words)])\n",
    "print(len(validate_dict))\n",
    "\n",
    "print(y_pred.shape)\n",
    "for i in range(len(y_pred)):\n",
    "    eval.top_ten_hundred(validate_dict, tgt_word[i], y_pred[i].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-04d9cb81fc15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(y_pred.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2, target)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/local_nmt/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_embedding_loss\u001b[0;34m(input1, input2, target, margin, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "definition_indices = vocab.words2indices(definitions)\n",
    "words_in = 0\n",
    "words_out = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "losses = []\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "for epoch in range(5000):\n",
    "    for src_sents, tgt_word in batch_iter(training_data, batch_size, False):\n",
    "        model.zero_grad()\n",
    "        x_lengths = [len(sent) for sent in src_sents]\n",
    "        x = vocab.to_input_tensor(src_sents, device)\n",
    "        init_hidden = model.initHidden(len(src_sents), device)\n",
    "        tag_scores = model.forward(x, init_hidden, x_lengths)\n",
    "        y_array = model.embedding.source[0](torch.tensor(vocab.words2indices(tgt_word))).double()\n",
    "        y_pred = tag_scores[0].squeeze(dim = 1).double()\n",
    "        y_match = torch.ones(1,)\n",
    "        #loss = loss_function(y_pred, y_array, y_match)\n",
    "        loss = l1loss(y_pred.transpose(0,1), y_array.transpose(0,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss)\n",
    "    print(epoch, loss, timeit.default_timer() - start)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(plt.plot([l.double() for l in losses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(plt.plot([l.double() for l in losses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "x_lengths = [len(sent) for sent in src_sents]\n",
    "x = vocab.to_input_tensor(src_sents, device)\n",
    "init_hidden = model.initHidden(len(src_sents), device)\n",
    "tag_scores = model.forward(x, init_hidden, x_lengths)\n",
    "y_pred = tag_scores[0].squeeze(dim = 1).double()\n",
    "\n",
    "validate_dict = dict([(w, model.embedding.source[0](torch.tensor(vocab[w])).detach().numpy()) for w in set(words)])\n",
    "print(len(validate_dict))\n",
    "\n",
    "print(y_pred.shape)\n",
    "for i in range(len(y_pred)):\n",
    "    eval.top_ten_hundred(validate_dict, tgt_word[i], y_pred[i].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
